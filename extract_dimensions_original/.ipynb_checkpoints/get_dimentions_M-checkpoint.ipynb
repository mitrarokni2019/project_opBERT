{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mitra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tendims\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded word embeddings from ./embeddings\\glove/glove.42B.300d.wv!\n",
      "Vocab size: 1917494\n",
      "Loaded word embeddings from ./embeddings\\word2vec/GoogleNews-vectors-negative300.wv!\n",
      "Vocab size: 3000000\n",
      "Loaded word embeddings from ./embeddings\\fasttext/wiki-news-300d-1M-subword.wv!\n",
      "Vocab size: 999994\n",
      "['support', 'knowledge', 'conflict', 'power', 'similarity', 'fun', 'status', 'trust', 'identity', 'romance']\n"
     ]
    }
   ],
   "source": [
    "model = tendims.TenDimensionsClassifier(is_cuda=False, models_dir = './models/lstm_trained_models', \n",
    "                                        embeddings_dir='./embeddings')\n",
    "dimensions = model.dimensions_list\n",
    "print(dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence-level classification\n",
    "\n",
    "The classifier was trained on individual sentences. Although the classifier accepts text of any length, we recommend to compute the scores sentence-by-sentence. The function compute_score_split does that for you and returns the maximum and average values. When using the maximum, please consider that the longer the text, the higher the likelihood to get a larger maximum value. So, if you use the maximum, be sure to account for text length in you analysis (i.e. a high maximum score on a text of 10 words is not comparable with the same value on a text of 100 words). You can always split the sentences yourself and aggregate sentence-level values as you deem appropriate.\n",
    "\n",
    "Score distribution\n",
    "\n",
    "The classifier returns confidence scores in the range [0,1]. This number is proportional to the likelihood of the text containing the selected dimension. Depending on the input data and on the aggregation performed, the empirical distributions of the confidence score may differ across dimensions (may be bell-shaped, skewed, bi-modal, etc.). For this reason, binarizing the scores based on a fixed threshold might not be the best approach. An approch that proved effective is to binarize based on a high percentile (e.g., 75th or 85th percentiles) computed on your empirical distribution of scores.\n",
    "\n",
    "Directionality\n",
    "\n",
    "The classifier was trained to identify expressions that \"convey\" dimension D from the speaker to the listener. For example, in the case of the dimension support, the classifier is supposed to find expressions indicating that the speaker is offering some support to the lister. In practice, this directionality is not guaranteed, and the classifier picks up different types of verbal expressions of the social dimensions. For example, \"I am willing to help you, whatever you need\" and \"Clara is willing to help George, whatever he needs\" have both relatively high scores for the dimension support (0.86 and 0.75, respectively), but only the first one is an expression of the speaker offering support. To more strongly enforce directionality, and approach that proved effective is to consider only sentences containing second-person pronouns.\n",
    "\n",
    "Errors\n",
    "\n",
    "Be aware that the classifier was trained mostly on Reddit data. It can be used on any piece of text but you should expect some performance drop when used on textual data with very different style or distribution of words (e.g., Twitter). Last, as everything in life, the classifications made by this tool are not perfect, but given eough data you'll be able to see interesting and meaningful trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9167402982711792, 0.9167402982711792, 0.9167402982711792, 0.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "model.compute_score_split('Hello, my name is Mike. I am willing to help you, whatever you need.', dimensions='support')\n",
    "# (np.mean(scores), np.max(scores), np.min(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing individual threads and comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>redditor_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>edited</th>\n",
       "      <th>removed</th>\n",
       "      <th>...</th>\n",
       "      <th>permalink</th>\n",
       "      <th>attachment</th>\n",
       "      <th>flair</th>\n",
       "      <th>awards</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>archived</th>\n",
       "      <th>poll</th>\n",
       "      <th>post_id_parent</th>\n",
       "      <th>redditor_id_parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpao0jn</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t3_rknr7b</td>\n",
       "      <td>hw76x</td>\n",
       "      <td>2021-12-20 15:10:36+00:00</td>\n",
       "      <td>&gt;Why should I stop flying when cruise ships ar...</td>\n",
       "      <td>{\"2024-11-01T13:01:45\":807}</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>suspended:British231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpanpbe</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t3_rknr7b</td>\n",
       "      <td>tz0epq1</td>\n",
       "      <td>2021-12-20 15:07:53+00:00</td>\n",
       "      <td>Why shouldn’t I toss my litter on the ground w...</td>\n",
       "      <td>{\"2024-11-01T13:01:45\":257}</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>suspended:British231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpaqa3x</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t3_rknr7b</td>\n",
       "      <td>xsbp7</td>\n",
       "      <td>2021-12-20 15:29:23+00:00</td>\n",
       "      <td>This is spite, however, it is misapplied.  The...</td>\n",
       "      <td>{\"2024-11-01T13:01:45\":53}</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>suspended:British231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpb48rk</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t3_rknr7b</td>\n",
       "      <td>4ena4pzw</td>\n",
       "      <td>2021-12-20 17:13:45+00:00</td>\n",
       "      <td>&gt;Why should I stop using my car and pay multip...</td>\n",
       "      <td>{\"2024-11-01T13:01:46\":61}</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>suspended:British231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpamqqh</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t3_rknr7b</td>\n",
       "      <td>d39pn2pj</td>\n",
       "      <td>2021-12-20 14:59:36+00:00</td>\n",
       "      <td>1. If everyone thinks as you do, then change i...</td>\n",
       "      <td>{\"2024-11-01T13:01:46\":1590}</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>suspended:British231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id link_id     subreddit  parent_id redditor_id  \\\n",
       "0  hpao0jn  rknr7b  changemyview  t3_rknr7b       hw76x   \n",
       "1  hpanpbe  rknr7b  changemyview  t3_rknr7b     tz0epq1   \n",
       "2  hpaqa3x  rknr7b  changemyview  t3_rknr7b       xsbp7   \n",
       "3  hpb48rk  rknr7b  changemyview  t3_rknr7b    4ena4pzw   \n",
       "4  hpamqqh  rknr7b  changemyview  t3_rknr7b    d39pn2pj   \n",
       "\n",
       "                  created_at  \\\n",
       "0  2021-12-20 15:10:36+00:00   \n",
       "1  2021-12-20 15:07:53+00:00   \n",
       "2  2021-12-20 15:29:23+00:00   \n",
       "3  2021-12-20 17:13:45+00:00   \n",
       "4  2021-12-20 14:59:36+00:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  >Why should I stop flying when cruise ships ar...   \n",
       "1  Why shouldn’t I toss my litter on the ground w...   \n",
       "2  This is spite, however, it is misapplied.  The...   \n",
       "3  >Why should I stop using my car and pay multip...   \n",
       "4  1. If everyone thinks as you do, then change i...   \n",
       "\n",
       "                          score  edited removed  ... permalink  attachment  \\\n",
       "0   {\"2024-11-01T13:01:45\":807}   False     NaN  ...       NaN         NaN   \n",
       "1   {\"2024-11-01T13:01:45\":257}   False     NaN  ...       NaN         NaN   \n",
       "2    {\"2024-11-01T13:01:45\":53}   False     NaN  ...       NaN         NaN   \n",
       "3    {\"2024-11-01T13:01:46\":61}   False     NaN  ...       NaN         NaN   \n",
       "4  {\"2024-11-01T13:01:46\":1590}   False     NaN  ...       NaN         NaN   \n",
       "\n",
       "  flair awards upvote_ratio  num_comments archived poll post_id_parent  \\\n",
       "0   NaN    NaN          NaN           NaN      NaN  NaN         rknr7b   \n",
       "1   NaN    NaN          NaN           NaN      NaN  NaN         rknr7b   \n",
       "2   NaN    NaN          NaN           NaN      NaN  NaN         rknr7b   \n",
       "3   NaN    NaN          NaN           NaN      NaN  NaN         rknr7b   \n",
       "4   NaN    NaN          NaN           NaN      NaN  NaN         rknr7b   \n",
       "\n",
       "     redditor_id_parent  \n",
       "0  suspended:British231  \n",
       "1  suspended:British231  \n",
       "2  suspended:British231  \n",
       "3  suspended:British231  \n",
       "4  suspended:British231  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load & read the data\n",
    "thread_rknr7b = pd.read_csv(\"../data/threads/rknr7b.csv\")\n",
    "thread_rknr7b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['post_id', 'link_id', 'subreddit', 'parent_id', 'redditor_id',\n",
      "       'created_at', 'body', 'score', 'edited', 'removed', 'parent_id_clean',\n",
      "       'has_delta', 'title', 'text', 'permalink', 'attachment', 'flair',\n",
      "       'awards', 'upvote_ratio', 'num_comments', 'archived', 'poll',\n",
      "       'post_id_parent', 'redditor_id_parent', 'body_length', 'num_chars',\n",
      "       'num_words', 'num_sentences', 'has_special_chars', 'special_chars',\n",
      "       'num_unique_words', 'avg_word_length'],\n",
      "      dtype='object')\n",
      "Number of rows in the DataFrame: 728\n"
     ]
    }
   ],
   "source": [
    "# Display all column names to confirm the cleaned body column's name\n",
    "print(thread_rknr7b.columns)\n",
    "\n",
    "# Get the number of rows in the DataFrame\n",
    "num_rows = thread_rknr7b.shape[0]\n",
    "print(\"Number of rows in the DataFrame:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******1\n",
      "Full Body Text of the First Entry:\n",
      " >Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?  \n",
      "\n",
      "If people stopped going on cruises, do you think they would still send cruise ships out?  \n",
      "\n",
      "&#x200B;\n",
      "\n",
      ">Why should I stop eating meat while people like Jeff Bezos are blasting off into space?\n",
      "\n",
      "If everyone cut out 50% of meat from their diets, what do you think that will do to total emissions from factory farms?  \n",
      "\n",
      "&#x200B;\n",
      "\n",
      "No one single person can make a difference, but the idea is if everyone together makes changes in their own personal life, the effect is greater than the individual contribution. Its not like these giant companies would continue to pollute for the fun of it.\n",
      "*******3\n",
      "Full Body Text of the third Entry:\n",
      " >Why should I stop using my car and pay multiple times more to use exorbitant trains?\n",
      "\n",
      "Actually, public transport is cheaper than owning a car.\n",
      "\n",
      ">Why should I stop eating meat while people like Jeff Bezos are blasting off into space?  \n",
      ">  \n",
      ">Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?\n",
      "\n",
      "At this point, personal lifestyle changes are not made to save the world singlehandedly. They are made to **normalize** eco-friendly behaviour. This is an important concept. If enough people make the choice for less carbon-heavy behaviours, it will become easier for society as a whole to sustain a low-carbon culture.\n",
      "\n",
      ">I'm not a climate change denier, I care about the climate. But I'm not going to significantly alter my life when these companies get away with what they're doing.\n",
      "\n",
      "It's just as bad to be an \"action-denier\" as a climate-change denier. Because both kinds of people end up doing the same thing - deterring society from moving in the right direction. Your consumer choices are supposed to influence the companies' choices. Supply and demand has to be at play here.\n",
      "\n",
      ">I think the whole backlash against climate change is most often not out of outright denial, but rather working class people are sick of being lectured by champagne socialists\n",
      "\n",
      "Why does anyone have to make their lifestyle choices about what someone else is doing as opposed to simply **what's right**? Why is everyone always trying to look at everyone else  rather than making independent, rational choices? (Trick question - this is exactly the reason why we need to **normalize** eco-friendly behaviors - because the rest of society are lazy copycats.)\n",
      "\n",
      "I highly recommend reading the following blog post that is both entertaining and articulates the flaws behind your reasoning: [https://hahatheworldisending.wordpress.com/2021/10/29/on-exposure-therapy/](https://hahatheworldisending.wordpress.com/2021/10/29/on-exposure-therapy/)\n",
      "*******5\n",
      "Full Body Text of the fifth Entry:\n",
      " I have seen your deltas on this, so I won’t address that companies are doing what they do to serve customers, but there is another reason:\n",
      "\n",
      "My wife had a friend over for dinner and she brought her husband, and we didn’t get along well. He was hard on me for driving a Ford Mustang, and when I asked, he drove a Honda Accord that got like 3mpg better fuel economy.\n",
      "\n",
      "I asked why he didn’t drive an electric car, and he said because they cost too much, and better tech was coming soon.\n",
      "\n",
      "I asked if he had solar panels on his roof, and then why not, and he gave the same excuse. They cost too much and better tech is on the way. I showed him a company in Texas that will put the solar panels on your roof at no cost. You don’t get to sell excess power, but you get a discount on power  usage and you are helping to build a green grid. \n",
      "\n",
      "He said he didn’t trust them, and didn’t want the holes in his roof.\n",
      "\n",
      "\n",
      "Now I am not a climate change denier either, but that seemed to be a really pathetic take on it. He advocated for mandating EV usage instead of gasoline powered cars, yet didn’t drive one. And he wouldn’t consider a no cost way to help produce power. He wants everyone else to feel the pain of change first, or at least at the same time, and to be blunt, his behavior is more likely to drive people away from his views instead of towards them.\n",
      "\n",
      "I have another friend who drives an EV. When our families drove to Florida for a vacation (from Texas) he rented a Tesla, demonstrating a long trip is possible in them with some charging stops. When we were in Pensacola he let us drive the Tesla and drove us around in it, it was cool. That is how people are convinced, by seeing the positives.\n",
      "\n",
      "* Who cares if Jeff Bezos goes to space? It is largely symbolic, but they are trying to work towards Mars, and to get there we are going to fire a lot of rockets into space. And space might have some solutions for problems we have today, if and when we are able to harvest materials from space and bring them back to Earth. Space travel is worth it.\n",
      "\n",
      "If you are thinking of not eating meat, then don’t eat meat. You do your part, and people are more likely to listen to you on the subject. And you might show people that you can live just fine on a plant based diet.\n",
      "\n",
      "Why should you stop flying because of cruise ships? Same reason. When famous people pushing for a carbon neutral life fly in private keys to climate conferences, many of us get a little irritated at them. If you think people shouldn’t get on a cruise ship, don’t get on one. If you think flying is a bad thing, don’t, there are options. But if your friends know you are flying, it will have a similar impact on their opinion of your beliefs on climate change.\n",
      "\n",
      "Your last paragraph backs this up, but it applies to job as well. The old saying “don’t throw rocks if you live in a glass house” applies, don’t lecture other people to live a life you won’t yourself. Not that you are lecturing, but if you think we need to change how we handle the environment, the best thing you can do is start by changing yourself and your own habits.\n",
      "\n",
      " *******\n",
      "Data type of 'body' column:\n",
      " object\n",
      "\n",
      " *******\n",
      "Summary of 'body' lengths:\n",
      " count     728.000000\n",
      "mean      401.579670\n",
      "std       543.978623\n",
      "min         0.000000\n",
      "25%       114.000000\n",
      "50%       243.500000\n",
      "75%       513.250000\n",
      "max      8803.000000\n",
      "Name: body_length, dtype: float64\n",
      "\n",
      "******* \n",
      "Sample rows with 'body' text and its length:\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           body  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    >Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?  \\n\\nIf people stopped going on cruises, do you think they would still send cruise ships out?  \\n\\n&#x200B;\\n\\n>Why should I stop eating meat while people like Jeff Bezos are blasting off into space?\\n\\nIf everyone cut out 50% of meat from their diets, what do you think that will do to total emissions from factory farms?  \\n\\n&#x200B;\\n\\nNo one single person can make a difference, but the idea is if everyone together makes changes in their own personal life, the effect is greater than the individual contribution. Its not like these giant companies would continue to pollute for the fun of it.   \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Why shouldn’t I toss my litter on the ground when companies release massive pollution?  Why should I bother donating a few bucks to charity when millions are starving?  Why should I wear a mask to protect the couple dozen people around me when millions don’t?  Why should I smile to my cashier when most people don’t even make eye contact?  \\n\\nBecause it’s the right thing to do, and the cumulative effect of lots of people doing the same isn’t negligible.  I bought an electric car not only for that reason, but because every dime I don’t spend on gas is one less dime of profit to the oil companies.  I also recycle, urge other people to take these things seriously, and vote.  I and the other people like me do make a difference.   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             This is spite, however, it is misapplied.  The logic should not be that the solution is not equitable therefore I won't participate in the solution.  It should be that it is not equitable therefore I will compel those companies to participate in the solution.\\n\\nAnother way to think about it are the communities that had nothing to do with the over consumption.  Climate change is an existential threat to them today.  You should consider answering to them, not the logic that satisfies your senses of spite.    \\n\\nYou think they forgive you and I for our over consumption of goods that harms them directly?   \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      >Why should I stop using my car and pay multiple times more to use exorbitant trains?\\n\\nActually, public transport is cheaper than owning a car.\\n\\n>Why should I stop eating meat while people like Jeff Bezos are blasting off into space?  \\n>  \\n>Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?\\n\\nAt this point, personal lifestyle changes are not made to save the world singlehandedly. They are made to **normalize** eco-friendly behaviour. This is an important concept. If enough people make the choice for less carbon-heavy behaviours, it will become easier for society as a whole to sustain a low-carbon culture.\\n\\n>I'm not a climate change denier, I care about the climate. But I'm not going to significantly alter my life when these companies get away with what they're doing.\\n\\nIt's just as bad to be an \"action-denier\" as a climate-change denier. Because both kinds of people end up doing the same thing - deterring society from moving in the right direction. Your consumer choices are supposed to influence the companies' choices. Supply and demand has to be at play here.\\n\\n>I think the whole backlash against climate change is most often not out of outright denial, but rather working class people are sick of being lectured by champagne socialists\\n\\nWhy does anyone have to make their lifestyle choices about what someone else is doing as opposed to simply **what's right**? Why is everyone always trying to look at everyone else  rather than making independent, rational choices? (Trick question - this is exactly the reason why we need to **normalize** eco-friendly behaviors - because the rest of society are lazy copycats.)\\n\\nI highly recommend reading the following blog post that is both entertaining and articulates the flaws behind your reasoning: [https://hahatheworldisending.wordpress.com/2021/10/29/on-exposure-therapy/](https://hahatheworldisending.wordpress.com/2021/10/29/on-exposure-therapy/)   \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1. If everyone thinks as you do, then change is not possible.\\n2. Helping *a little bit* is better than no help at all.\\n3. Reducing your meat consumption and walking or using public transportation when possible will neither change nor impact your life in any significant way.   \n",
      "5  I have seen your deltas on this, so I won’t address that companies are doing what they do to serve customers, but there is another reason:\\n\\nMy wife had a friend over for dinner and she brought her husband, and we didn’t get along well. He was hard on me for driving a Ford Mustang, and when I asked, he drove a Honda Accord that got like 3mpg better fuel economy.\\n\\nI asked why he didn’t drive an electric car, and he said because they cost too much, and better tech was coming soon.\\n\\nI asked if he had solar panels on his roof, and then why not, and he gave the same excuse. They cost too much and better tech is on the way. I showed him a company in Texas that will put the solar panels on your roof at no cost. You don’t get to sell excess power, but you get a discount on power  usage and you are helping to build a green grid. \\n\\nHe said he didn’t trust them, and didn’t want the holes in his roof.\\n\\n\\nNow I am not a climate change denier either, but that seemed to be a really pathetic take on it. He advocated for mandating EV usage instead of gasoline powered cars, yet didn’t drive one. And he wouldn’t consider a no cost way to help produce power. He wants everyone else to feel the pain of change first, or at least at the same time, and to be blunt, his behavior is more likely to drive people away from his views instead of towards them.\\n\\nI have another friend who drives an EV. When our families drove to Florida for a vacation (from Texas) he rented a Tesla, demonstrating a long trip is possible in them with some charging stops. When we were in Pensacola he let us drive the Tesla and drove us around in it, it was cool. That is how people are convinced, by seeing the positives.\\n\\n* Who cares if Jeff Bezos goes to space? It is largely symbolic, but they are trying to work towards Mars, and to get there we are going to fire a lot of rockets into space. And space might have some solutions for problems we have today, if and when we are able to harvest materials from space and bring them back to Earth. Space travel is worth it.\\n\\nIf you are thinking of not eating meat, then don’t eat meat. You do your part, and people are more likely to listen to you on the subject. And you might show people that you can live just fine on a plant based diet.\\n\\nWhy should you stop flying because of cruise ships? Same reason. When famous people pushing for a carbon neutral life fly in private keys to climate conferences, many of us get a little irritated at them. If you think people shouldn’t get on a cruise ship, don’t get on one. If you think flying is a bad thing, don’t, there are options. But if your friends know you are flying, it will have a similar impact on their opinion of your beliefs on climate change.\\n\\nYour last paragraph backs this up, but it applies to job as well. The old saying “don’t throw rocks if you live in a glass house” applies, don’t lecture other people to live a life you won’t yourself. Not that you are lecturing, but if you think we need to change how we handle the environment, the best thing you can do is start by changing yourself and your own habits.   \n",
      "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      The big companies only react to demand. If everyone does their part, companies will react as well. Nothing is isolated, it’s all connected. I saw a doc on this exact point and it explained how it’s actually important we do our part.   \n",
      "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               >Why should I stop using my car and pay multiple times more to use exorbitant trains\\n\\nA 30 day pass for Chicago's train system [costs $75](https://www.transitchicago.com/passes/). Average monthly car payment is [$563](https://www.lendingtree.com/auto/how-much-does-a-car-cost/#:~:text=In%202021%2C%20the%20average%20car,Kelley%20Blue%20Book%20and%20LendingTree.). Plus all the additional costs of car use (fuel, maintenance, insurance, parking, pithy bumper stickers, and so on) mean that driving a car is even more expensive than above. How much are the trains where you live? \\n\\n>Why should I stop eating meat while people like Jeff Bezos are blasting off into space\\n\\n\"[Social media users tweeted that Bezos’ brief trip to space released 300 metric tons of carbon dioxide. The trip released none. The rocket’s engine burns hydrogen and oxygen to carry it away from Earth.](https://www.politifact.com/factchecks/2021/jul/20/tweets/how-much-co2-did-bezos-rocket-ride-release-close-z/)\"\\n\\n\"[An Average American’s diet has a foodprint of around 2.5 t CO2e per person each year.  For a Meat Lover this rises to 3.3 t CO2e](https://shrinkthatfootprint.com/food-carbon-footprint-diet)\"\\n\\nIt looks like your personal meat eating has a larger carbon footprint that Bezos's space penis launching.   \n",
      "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          I have a lot to say about the psychological dynamics of this, but let me start here: \\n\\nHere in the US, what we call \"regular people\" are actually among the very wealthiest and greatest emitters of greenhouse gases in the world. A family of four, say, with a firefighter and a teacher as parents, will be earning roughly $100,000 a year. That's roughly 33x the median household income in India, and 15x the median household income in China. \\n\\nEven though it's not Bezos kind of money, by global standards that family is fabulously wealthy. So why is it unreasonable to ask that that family make some modest lifestyle changes to reduce their carbon footprint? \\n\\nSetting all that aside, if you told your kid to clean up his room and he said he shouldn't have to because his classmate Jeff has a housekeeper and he never has to clean up his room, you wouldn't accept that, would you? Your logic isn't really all that different. You can't control what other people do; you can only control your own behavior. If you legitimately are concerned about climate change, why not make changes to your lifestyle in order to make it better? Why not serve as an example to others of how to behave?   \n",
      "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Indeed do something better. Be politically active, fight for our survival, change peoples mind, disrupt greedy corporations,  sacrifice for humanity and you'll find you're not alone   \n",
      "\n",
      "   body_length  \n",
      "0          718  \n",
      "1          731  \n",
      "2          605  \n",
      "3         1990  \n",
      "4          274  \n",
      "5         3095  \n",
      "6          232  \n",
      "7         1285  \n",
      "8         1182  \n",
      "9          181  \n"
     ]
    }
   ],
   "source": [
    "# Display the full content of the 'body' for the first row to avoid truncation\n",
    "\n",
    "# Set display option to show full text in columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"*******1\\nFull Body Text of the First Entry:\\n\", thread_rknr7b.loc[0, \"body\"])\n",
    "print(\"*******3\\nFull Body Text of the third Entry:\\n\", thread_rknr7b.loc[3, \"body\"])\n",
    "print(\"*******5\\nFull Body Text of the fifth Entry:\\n\", thread_rknr7b.loc[5, \"body\"])\n",
    "\n",
    "# Check the data type of the 'body' column\n",
    "print(\"\\n *******\\nData type of 'body' column:\\n\", thread_rknr7b[\"body\"].dtype)\n",
    "\n",
    "# Fill NaN values in 'body' with an empty string before calculating the length\n",
    "thread_rknr7b[\"body\"] = thread_rknr7b[\"body\"].fillna(\"\")\n",
    "\n",
    "# Calculate the length of the text in 'body' for each entry and add it as a new column\n",
    "thread_rknr7b[\"body_length\"] = thread_rknr7b[\"body\"].apply(len)\n",
    "\n",
    "\n",
    "# Show summary statistics for the body lengths\n",
    "print(\"\\n *******\\nSummary of 'body' lengths:\\n\", thread_rknr7b[\"body_length\"].describe())\n",
    "\n",
    "# Display the first few rows to inspect the 'body_length' column\n",
    "print(\"\\n******* \\nSample rows with 'body' text and its length:\\n\")\n",
    "print(thread_rknr7b[[\"body\", \"body_length\"]].head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format 1> analyze_text\n",
    "# Define a function to calculate additional metrics and check for special characters\n",
    "def analyze_text(text):\n",
    "    num_chars = len(text) if isinstance(text, str) else 0\n",
    "    num_words = len(text.split()) if isinstance(text, str) else 0\n",
    "    num_sentences = len(re.split(r'[.!?]', text)) - 1 if isinstance(text, str) else 0\n",
    "    has_special_chars = bool(re.search(r'[\\[\\]\\{\\}\\*\\&]', text)) if isinstance(text, str) else False  # Check for special characters\n",
    "    return pd.Series({\n",
    "        \"num_chars\": num_chars,\n",
    "        \"num_words\": num_words,\n",
    "        \"num_sentences\": num_sentences,\n",
    "        \"has_special_chars\": has_special_chars\n",
    "    })\n",
    "\n",
    "# Apply the function to each row in 'body' and store results in new columns\n",
    "thread_rknr7b[[\"num_chars\", \"num_words\", \"num_sentences\", \"has_special_chars\"]] = thread_rknr7b[\"body\"].apply(analyze_text)\n",
    "\n",
    "# Display the extracted metrics table without the 'body' column\n",
    "print(thread_rknr7b[[\"num_chars\", \"num_words\", \"num_sentences\", \"has_special_chars\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format 2> analyze_text\n",
    "# Define the function to analyze text\n",
    "def analyze_text_with_special_chars(text):\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        special_chars = re.findall(r'[^\\w\\s\\.\\?\\!]', text)  # Find characters that aren't alphanumeric, space, ., ?, !\n",
    "        has_special_chars = len(special_chars) > 0\n",
    "        return pd.Series({\n",
    "            \"num_chars\": len(text),\n",
    "            \"num_words\": len(text.split()),\n",
    "            \"num_sentences\": len(re.split(r'[.!?]', text)) - 1,\n",
    "            \"has_special_chars\": has_special_chars,\n",
    "            \"special_chars\": ''.join(set(special_chars))  # Unique special characters\n",
    "        })\n",
    "    else:\n",
    "        return pd.Series({\n",
    "            \"num_chars\": 0,\n",
    "            \"num_words\": 0,\n",
    "            \"num_sentences\": 0,\n",
    "            \"has_special_chars\": False,\n",
    "            \"special_chars\": \"\"\n",
    "        })\n",
    "    \n",
    "# Display other statistical features if needed\n",
    "print(\"\\nAdditional Features:\")\n",
    "print(\"Number of Words in 'body':\", len(body_text.split()))\n",
    "print(\"Number of Unique Words in 'body':\", len(set(body_text.split())))\n",
    "print(\"Average Word Length in 'body':\", sum(len(word) for word in body_text.split()) / len(body_text.split()))\n",
    "\n",
    "# Apply the function to each row in 'body' and store results in new columns\n",
    "thread_rknr7b[[\"num_chars\", \"num_words\", \"num_sentences\", \"has_special_chars\", \"special_chars\"]] = thread_rknr7b[\"body\"].apply(analyze_text_with_special_chars)\n",
    "\n",
    "# Display the metrics without the body content\n",
    "print(thread_rknr7b[[\"num_chars\", \"num_words\", \"num_sentences\", \"has_special_chars\", \"special_chars\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_chars  num_words  num_sentences  has_special_chars special_chars  \\\n",
      "0        718        125              6               True        ,>#;&%   \n",
      "1        731        133              8               True            ’,   \n",
      "2        605        103              7               True            ,'   \n",
      "3       1990        305             21               True  )]*(,[>:'/-\"   \n",
      "4        274         48              6               True            *,   \n",
      "\n",
      "   num_unique_words  avg_word_length  \n",
      "0                94         4.656000  \n",
      "1                89         4.436090  \n",
      "2                65         4.786408  \n",
      "3               207         5.485246  \n",
      "4                45         4.729167  \n"
     ]
    }
   ],
   "source": [
    "# format 3> analyze_text\n",
    "\n",
    "# Define the function to analyze text\n",
    "def analyze_text_with_special_chars(text):\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        # Find special characters that aren't alphanumeric, spaces, ., ?, !\n",
    "        special_chars = re.findall(r'[^\\w\\s\\.\\?\\!]', text)\n",
    "        has_special_chars = len(special_chars) > 0\n",
    "        words = text.split()\n",
    "        \n",
    "        # Calculate unique words and average word length\n",
    "        num_unique_words = len(set(words))\n",
    "        avg_word_length = sum(len(word) for word in words) / len(words) if words else 0\n",
    "\n",
    "        return pd.Series({\n",
    "            \"num_chars\": len(text),\n",
    "            \"num_words\": len(words),\n",
    "            \"num_sentences\": len(re.split(r'[.!?]', text)) - 1,\n",
    "            \"has_special_chars\": has_special_chars,\n",
    "            \"special_chars\": ''.join(set(special_chars)),  # Unique special characters\n",
    "            \"num_unique_words\": num_unique_words,\n",
    "            \"avg_word_length\": avg_word_length\n",
    "        })\n",
    "    else:\n",
    "        # Handle non-string entries\n",
    "        return pd.Series({\n",
    "            \"num_chars\": 0,\n",
    "            \"num_words\": 0,\n",
    "            \"num_sentences\": 0,\n",
    "            \"has_special_chars\": False,\n",
    "            \"special_chars\": \"\",\n",
    "            \"num_unique_words\": 0,\n",
    "            \"avg_word_length\": 0\n",
    "        })\n",
    "\n",
    "# Apply the function to each row in 'body' and store results in new columns\n",
    "thread_rknr7b[[\"num_chars\", \"num_words\", \"num_sentences\", \"has_special_chars\", \"special_chars\", \n",
    "               \"num_unique_words\", \"avg_word_length\"]] = thread_rknr7b[\"body\"].apply(analyze_text_with_special_chars)\n",
    "\n",
    "# Display the metrics without the body content\n",
    "print(thread_rknr7b[[\"num_chars\", \"num_words\", \"num_sentences\", \"has_special_chars\", \n",
    "                     \"special_chars\", \"num_unique_words\", \"avg_word_length\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?  \n",
      "\n",
      "If people stopped going on cruises, do you think they would still send cruise ships out?  \n",
      "\n",
      "&#x200B;\n",
      "\n",
      ">Why should I stop eating meat while people like Jeff Bezos are blasting off into space?\n",
      "\n",
      "If everyone cut out 50% of meat from their diets, what do you think that will do to total emissions from factory farms?  \n",
      "\n",
      "&#x200B;\n",
      "\n",
      "No one single person can make a difference, but the idea is if everyone together makes changes in their own personal life, the effect is greater than the individual contribution. Its not like these giant companies would continue to pollute for the fun of it.\n"
     ]
    }
   ],
   "source": [
    "#Let's fisrt work on the first bodey now >   body[0] is uor sample :\n",
    "# Display the full content of the 'body' column for the first row\n",
    "body_text1 = thread_rknr7b.loc[0, \"body\"]  # Access the full text of the first entry\n",
    "print(body_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'body': <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Check the type of the 'body' content\n",
    "print(\"Type of 'body':\", type(body_text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of 'body': 718\n",
      "Last part of text: vidual contribution. Its not like these giant companies would continue to pollute for the fun of it.\n"
     ]
    }
   ],
   "source": [
    "# Check the length\n",
    "print(\"Length of 'body':\", len(body_text1))\n",
    "\n",
    "# Display the last 100 characters to confirm if there’s more to the text\n",
    "print(\"Last part of text:\", body_text1[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>redditor_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>edited</th>\n",
       "      <th>removed</th>\n",
       "      <th>...</th>\n",
       "      <th>post_id_parent</th>\n",
       "      <th>redditor_id_parent</th>\n",
       "      <th>body_length</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>has_special_chars</th>\n",
       "      <th>special_chars</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpao0jn</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t3_rknr7b</td>\n",
       "      <td>hw76x</td>\n",
       "      <td>2021-12-20 15:10:36+00:00</td>\n",
       "      <td>&gt;Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?  \\n\\nIf people stopped going on cruises, do you think they would still send cruise ships out?  \\n\\n&amp;#x200B;\\n\\n&gt;Why should I stop eating meat while people like Jeff Bezos are blasting off into space?\\n\\nIf everyone cut out 50% of meat from their diets, what do you think that will do to total emissions from factory farms?  \\n\\n&amp;#x200B;\\n\\nNo one single person can make a difference, but the idea is if everyone together makes changes in their own personal life, the effect is greater than the individual contribution. Its not like these giant companies would continue to pollute for the fun of it.</td>\n",
       "      <td>{\"2024-11-01T13:01:45\":807}</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>suspended:British231</td>\n",
       "      <td>718</td>\n",
       "      <td>718</td>\n",
       "      <td>125</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>,&gt;#;&amp;%</td>\n",
       "      <td>94</td>\n",
       "      <td>4.656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id link_id     subreddit  parent_id redditor_id  \\\n",
       "0  hpao0jn  rknr7b  changemyview  t3_rknr7b       hw76x   \n",
       "\n",
       "                  created_at  \\\n",
       "0  2021-12-20 15:10:36+00:00   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         body  \\\n",
       "0  >Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?  \\n\\nIf people stopped going on cruises, do you think they would still send cruise ships out?  \\n\\n&#x200B;\\n\\n>Why should I stop eating meat while people like Jeff Bezos are blasting off into space?\\n\\nIf everyone cut out 50% of meat from their diets, what do you think that will do to total emissions from factory farms?  \\n\\n&#x200B;\\n\\nNo one single person can make a difference, but the idea is if everyone together makes changes in their own personal life, the effect is greater than the individual contribution. Its not like these giant companies would continue to pollute for the fun of it.   \n",
       "\n",
       "                         score  edited removed  ... post_id_parent  \\\n",
       "0  {\"2024-11-01T13:01:45\":807}   False     NaN  ...         rknr7b   \n",
       "\n",
       "     redditor_id_parent body_length num_chars num_words  num_sentences  \\\n",
       "0  suspended:British231         718       718       125              6   \n",
       "\n",
       "  has_special_chars special_chars num_unique_words avg_word_length  \n",
       "0              True        ,>#;&%               94           4.656  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where 'has_delta' is 1\n",
    "delta_rows = thread_rknr7b[thread_rknr7b['has_delta'] == 1]\n",
    "\n",
    "delta_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    726\n",
      "1.0      1\n",
      "Name: has_delta, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count rows with has_delta as 0 and 1\n",
    "delta_counts= thread_rknr7b['has_delta'].value_counts()\n",
    "print(delta_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>has_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?  \\n\\nIf people stopped going on cruises, do you think they would still send cruise ships out?  \\n\\n&amp;#x200B;\\n\\n&gt;Why should I stop eating meat while people like Jeff Bezos are blasting off into space?\\n\\nIf everyone cut out 50% of meat from their diets, what do you think that will do to total emissions from factory farms?  \\n\\n&amp;#x200B;\\n\\nNo one single person can make a difference, but the idea is if everyone together makes changes in their own personal life, the effect is greater than the individual contribution. Its not like these giant companies would continue to pollute for the fun of it.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         body  \\\n",
       "0  >Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?  \\n\\nIf people stopped going on cruises, do you think they would still send cruise ships out?  \\n\\n&#x200B;\\n\\n>Why should I stop eating meat while people like Jeff Bezos are blasting off into space?\\n\\nIf everyone cut out 50% of meat from their diets, what do you think that will do to total emissions from factory farms?  \\n\\n&#x200B;\\n\\nNo one single person can make a difference, but the idea is if everyone together makes changes in their own personal life, the effect is greater than the individual contribution. Its not like these giant companies would continue to pollute for the fun of it.   \n",
       "\n",
       "   has_delta  \n",
       "0        1.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where has_delta is 1 and display the first few\n",
    "delta_rows_sample = thread_rknr7b[thread_rknr7b['has_delta'] == 1].head(4)\n",
    "\n",
    "# Display the 'body' column and other relevant columns if needed\n",
    "delta_rows_sample[['body', 'has_delta']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>redditor_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>edited</th>\n",
       "      <th>removed</th>\n",
       "      <th>...</th>\n",
       "      <th>post_id_parent</th>\n",
       "      <th>redditor_id_parent</th>\n",
       "      <th>body_length</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>has_special_chars</th>\n",
       "      <th>special_chars</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpao0jn</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t3_rknr7b</td>\n",
       "      <td>hw76x</td>\n",
       "      <td>2021-12-20 15:10:36+00:00</td>\n",
       "      <td>&gt;Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?  \\n\\nIf people stopped going on cruises, do you think they would still send cruise ships out?  \\n\\n&amp;#x200B;\\n\\n&gt;Why should I stop eating meat while people like Jeff Bezos are blasting off into space?\\n\\nIf everyone cut out 50% of meat from their diets, what do you think that will do to total emissions from factory farms?  \\n\\n&amp;#x200B;\\n\\nNo one single person can make a difference, but the idea is if everyone together makes changes in their own personal life, the effect is greater than the individual contribution. Its not like these giant companies would continue to pollute for the fun of it.</td>\n",
       "      <td>{\"2024-11-01T13:01:45\":807}</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>suspended:British231</td>\n",
       "      <td>718</td>\n",
       "      <td>718</td>\n",
       "      <td>125</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>,&gt;#;&amp;%</td>\n",
       "      <td>94</td>\n",
       "      <td>4.656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id link_id     subreddit  parent_id redditor_id  \\\n",
       "0  hpao0jn  rknr7b  changemyview  t3_rknr7b       hw76x   \n",
       "\n",
       "                  created_at  \\\n",
       "0  2021-12-20 15:10:36+00:00   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         body  \\\n",
       "0  >Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?  \\n\\nIf people stopped going on cruises, do you think they would still send cruise ships out?  \\n\\n&#x200B;\\n\\n>Why should I stop eating meat while people like Jeff Bezos are blasting off into space?\\n\\nIf everyone cut out 50% of meat from their diets, what do you think that will do to total emissions from factory farms?  \\n\\n&#x200B;\\n\\nNo one single person can make a difference, but the idea is if everyone together makes changes in their own personal life, the effect is greater than the individual contribution. Its not like these giant companies would continue to pollute for the fun of it.   \n",
       "\n",
       "                         score  edited removed  ... post_id_parent  \\\n",
       "0  {\"2024-11-01T13:01:45\":807}   False     NaN  ...         rknr7b   \n",
       "\n",
       "     redditor_id_parent body_length num_chars num_words  num_sentences  \\\n",
       "0  suspended:British231         718       718       125              6   \n",
       "\n",
       "  has_special_chars special_chars num_unique_words avg_word_length  \n",
       "0              True        ,>#;&%               94           4.656  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_with_delta = thread_rknr7b[thread_rknr7b['has_delta'] == 1]\n",
    "posts_with_delta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comment = posts_with_delta.iloc[0]['body']\n",
    "print(test_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_and_split_text(text):\n",
    "    # Remove special characters except ., ?, !\n",
    "    text = re.sub(r'[^\\w\\s\\.\\?\\!]', '', text)  \n",
    "    \n",
    "    # Split into sentences based on punctuation marks and clean up spaces\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    \n",
    "    # Remove empty sentences and ensure they are properly formatted\n",
    "    clean_sentences = [sentence.strip() for sentence in sentences if sentence]\n",
    "    \n",
    "    return clean_sentences\n",
    "\n",
    "# Apply the cleaning function to the 'body' column and add the result as a new column\n",
    "thread_rknr7b[\"clean_body\"] = thread_rknr7b[\"body\"].apply(clean_and_split_text)\n",
    "\n",
    "# Display the cleaned and split body\n",
    "print(thread_rknr7b[[\"body\", \"clean_body\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Body:\n",
      " >Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?  \n",
      "\n",
      "If people stopped going on cruises, do you think they would still send cruise ships out?  \n",
      "\n",
      "&#x200B;\n",
      "\n",
      ">Why should I stop eating meat while people like Jeff Bezos are blasting off into space?\n",
      "\n",
      "If everyone cut out 50% of meat from their diets, what do you think that will do to total emissions from factory farms?  \n",
      "\n",
      "&#x200B;\n",
      "\n",
      "No one single person can make a difference, but the idea is if everyone together makes changes in their own personal life, the effect is greater than the individual contribution. Its not like these giant companies would continue to pollute for the fun of it.\n",
      "\n",
      "Cleaned and Split Sentences:\n",
      " ['Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?', 'If people stopped going on cruises do you think they would still send cruise ships out?', 'Why should I stop eating meat while people like Jeff Bezos are blasting off into space?', 'If everyone cut out 50 of meat from their diets what do you think that will do to total emissions from factory farms?', 'No one single person can make a difference but the idea is if everyone together makes changes in their own personal life the effect is greater than the individual contribution.', 'Its not like these giant companies would continue to pollute for the fun of it.']\n"
     ]
    }
   ],
   "source": [
    "def clean_and_split_text_improved(text):\n",
    "    # Remove special characters except ., ?, !\n",
    "    text = re.sub(r'&#x200B;|\\n|\\t', ' ', text)  # Removes specific placeholders and newline characters\n",
    "    text = re.sub(r'[^\\w\\s\\.\\?\\!]', '', text)  # Removes all other special characters except ., ?, !\n",
    "    \n",
    "    # Split into sentences based on punctuation marks and clean up spaces\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    \n",
    "    # Remove empty sentences and ensure they are properly formatted\n",
    "    clean_sentences = [sentence.strip() for sentence in sentences if sentence]\n",
    "    \n",
    "    return clean_sentences\n",
    "\n",
    "# Apply the improved cleaning function to the 'body' column\n",
    "thread_rknr7b[\"clean_body\"] = thread_rknr7b[\"body\"].apply(clean_and_split_text_improved)\n",
    "\n",
    "# Display the comparison of the first entry\n",
    "print(\"Original Body:\\n\", thread_rknr7b[\"body\"].iloc[0])\n",
    "print(\"\\nCleaned and Split Sentences:\\n\", thread_rknr7b[\"clean_body\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Body:\n",
      " >Why should I stop using my car and pay multiple times more to use exorbitant trains?\n",
      "\n",
      "Actually, public transport is cheaper than owning a car.\n",
      "\n",
      ">Why should I stop eating meat while people like Jeff Bezos are blasting off into space?  \n",
      ">  \n",
      ">Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?\n",
      "\n",
      "At this point, personal lifestyle changes are not made to save the world singlehandedly. They are made to **normalize** eco-friendly behaviour. This is an important concept. If enough people make the choice for less carbon-heavy behaviours, it will become easier for society as a whole to sustain a low-carbon culture.\n",
      "\n",
      ">I'm not a climate change denier, I care about the climate. But I'm not going to significantly alter my life when these companies get away with what they're doing.\n",
      "\n",
      "It's just as bad to be an \"action-denier\" as a climate-change denier. Because both kinds of people end up doing the same thing - deterring society from moving in the right direction. Your consumer choices are supposed to influence the companies' choices. Supply and demand has to be at play here.\n",
      "\n",
      ">I think the whole backlash against climate change is most often not out of outright denial, but rather working class people are sick of being lectured by champagne socialists\n",
      "\n",
      "Why does anyone have to make their lifestyle choices about what someone else is doing as opposed to simply **what's right**? Why is everyone always trying to look at everyone else  rather than making independent, rational choices? (Trick question - this is exactly the reason why we need to **normalize** eco-friendly behaviors - because the rest of society are lazy copycats.)\n",
      "\n",
      "I highly recommend reading the following blog post that is both entertaining and articulates the flaws behind your reasoning: [https://hahatheworldisending.wordpress.com/2021/10/29/on-exposure-therapy/](https://hahatheworldisending.wordpress.com/2021/10/29/on-exposure-therapy/)\n",
      "\n",
      "Advanced Cleaned and Split Sentences:\n",
      " ['Why should I stop using my car and pay multiple times more to use exorbitant trains?', 'Actually public transport is cheaper than owning a car.', 'Why should I stop eating meat while people like Jeff Bezos are blasting off into space?', 'Why should I stop flying when cruise ships are out and about pumping more CO2 into the atmosphere than thousands of cars combined?', 'At this point personal lifestyle changes are not made to save the world singlehandedly.', 'They are made to normalize ecofriendly behaviour.', 'This is an important concept.', 'If enough people make the choice for less carbonheavy behaviours it will become easier for society as a whole to sustain a lowcarbon culture.', 'Im not a climate change denier I care about the climate.', 'But Im not going to significantly alter my life when these companies get away with what theyre doing.', 'Its just as bad to be an actiondenier as a climatechange denier.', 'Because both kinds of people end up doing the same thing  deterring society from moving in the right direction.', 'Your consumer choices are supposed to influence the companies choices.', 'Supply and demand has to be at play here.', 'I think the whole backlash against climate change is most often not out of outright denial but rather working class people are sick of being lectured by champagne socialists  Why does anyone have to make their lifestyle choices about what someone else is doing as opposed to simply whats right?', 'Why is everyone always trying to look at everyone else  rather than making independent rational choices?', 'Trick question  this is exactly the reason why we need to normalize ecofriendly behaviors  because the rest of society are lazy copycats.', 'I highly recommend reading the following blog post that is both entertaining and articulates the flaws behind your reasoning']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def clean_and_split_text_improved(text):\n",
    "    # Remove special characters except ., ?, !\n",
    "    text = re.sub(r'&#x200B;|\\n|\\t', ' ', text)  # Removes specific placeholders and newline characters\n",
    "    text = re.sub(r'[^\\w\\s\\.\\?\\!]', '', text)  # Removes all other special characters except ., ?, !\n",
    "    \n",
    "    # Split into sentences based on punctuation marks and clean up spaces\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    \n",
    "    # Remove empty sentences and ensure they are properly formatted\n",
    "    clean_sentences = [sentence.strip() for sentence in sentences if sentence]\n",
    "    \n",
    "    return clean_sentences\n",
    "\n",
    "# Apply the improved cleaning function to the 'body' column\n",
    "thread_rknr7b[\"clean_body\"] = thread_rknr7b[\"body\"].apply(clean_and_split_text_improved)\n",
    "\n",
    "# Display the comparison of the first entry\n",
    "print(\"Original Body:\\n\", thread_rknr7b[\"body\"].iloc[0])\n",
    "print(\"\\nCleaned and Split Sentences:\\n\", thread_rknr7b[\"clean_body\"].iloc[0])\n",
    "'''\n",
    "\n",
    "def advanced_clean_and_split_text(text):\n",
    "    text = re.sub(r'&#x200B;|\\n|\\t', ' ', text)  # Remove specific placeholders, newline characters, and tabs\n",
    "    text = re.sub(r'http\\S+', '', text)   # Remove URLs\n",
    "    #text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)  # Insert spaces where lowercase and uppercase letters are merged\n",
    "    #text = re.sub(r\"\\bIm\\b\", \"I'm\", text) # Handle common contractions (expand or correct them)\n",
    "    #text = re.sub(r\"\\bIts\\b\", \"It's\", text) # Handle common contractions (expand or correct them)\n",
    "    #text = re.sub(r\"\\bDont\\b\", \"Don't\", text)  # Handle common contractions (expand or correct them)\n",
    "    text = re.sub(r'[^\\w\\s\\.\\?\\!]', '', text)  # Remove other special characters except ., ?, !\n",
    "    \n",
    "    # Split into sentences based on punctuation marks\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    # Clean up spaces and filter out any empty sentences\n",
    "    clean_sentences = [sentence.strip() for sentence in sentences if sentence]\n",
    "    return clean_sentences\n",
    "\n",
    "# Apply this new cleaning function to the 'body' column\n",
    "thread_rknr7b[\"clean_body\"] = thread_rknr7b[\"body\"].apply(advanced_clean_and_split_text)\n",
    "\n",
    "# Display the comparison of the third entry to check improvements\n",
    "print(\"Original Body:\\n\", thread_rknr7b[\"body\"].iloc[3])\n",
    "print(\"\\nAdvanced Cleaned and Split Sentences:\\n\", thread_rknr7b[\"clean_body\"].iloc[3])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>redditor_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>edited</th>\n",
       "      <th>removed</th>\n",
       "      <th>parent_id_clean</th>\n",
       "      <th>has_delta</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>permalink</th>\n",
       "      <th>attachment</th>\n",
       "      <th>flair</th>\n",
       "      <th>awards</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>archived</th>\n",
       "      <th>poll</th>\n",
       "      <th>post_id_parent</th>\n",
       "      <th>redditor_id_parent</th>\n",
       "      <th>body_length</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>has_special_chars</th>\n",
       "      <th>special_chars</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>clean_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpao0jn</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t3_rknr7b</td>\n",
       "      <td>hw76x</td>\n",
       "      <td>2021-12-20 15:10:36+00:00</td>\n",
       "      <td>&gt;Why should I stop flying when cruise ships ar...</td>\n",
       "      <td>{\"2024-11-01T13:01:45\":807}</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>suspended:British231</td>\n",
       "      <td>718</td>\n",
       "      <td>718</td>\n",
       "      <td>125</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>,&gt;#;&amp;%</td>\n",
       "      <td>94</td>\n",
       "      <td>4.656000</td>\n",
       "      <td>[Why should I stop flying when cruise ships ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpanpbe</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t3_rknr7b</td>\n",
       "      <td>tz0epq1</td>\n",
       "      <td>2021-12-20 15:07:53+00:00</td>\n",
       "      <td>Why shouldn’t I toss my litter on the ground w...</td>\n",
       "      <td>{\"2024-11-01T13:01:45\":257}</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>suspended:British231</td>\n",
       "      <td>731</td>\n",
       "      <td>731</td>\n",
       "      <td>133</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>’,</td>\n",
       "      <td>89</td>\n",
       "      <td>4.436090</td>\n",
       "      <td>[Why shouldnt I toss my litter on the ground w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpaqa3x</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t3_rknr7b</td>\n",
       "      <td>xsbp7</td>\n",
       "      <td>2021-12-20 15:29:23+00:00</td>\n",
       "      <td>This is spite, however, it is misapplied.  The...</td>\n",
       "      <td>{\"2024-11-01T13:01:45\":53}</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>suspended:British231</td>\n",
       "      <td>605</td>\n",
       "      <td>605</td>\n",
       "      <td>103</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>,'</td>\n",
       "      <td>65</td>\n",
       "      <td>4.786408</td>\n",
       "      <td>[This is spite however it is misapplied., The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpb48rk</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t3_rknr7b</td>\n",
       "      <td>4ena4pzw</td>\n",
       "      <td>2021-12-20 17:13:45+00:00</td>\n",
       "      <td>&gt;Why should I stop using my car and pay multip...</td>\n",
       "      <td>{\"2024-11-01T13:01:46\":61}</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>suspended:British231</td>\n",
       "      <td>1990</td>\n",
       "      <td>1990</td>\n",
       "      <td>305</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>)]*(,[&gt;:'/-\"</td>\n",
       "      <td>207</td>\n",
       "      <td>5.485246</td>\n",
       "      <td>[Why should I stop using my car and pay multip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpamqqh</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t3_rknr7b</td>\n",
       "      <td>d39pn2pj</td>\n",
       "      <td>2021-12-20 14:59:36+00:00</td>\n",
       "      <td>1. If everyone thinks as you do, then change i...</td>\n",
       "      <td>{\"2024-11-01T13:01:46\":1590}</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rknr7b</td>\n",
       "      <td>suspended:British231</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>*,</td>\n",
       "      <td>45</td>\n",
       "      <td>4.729167</td>\n",
       "      <td>[1., If everyone thinks as you do then change ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id link_id     subreddit  parent_id redditor_id                 created_at                                               body                         score  edited removed parent_id_clean  has_delta title text permalink  attachment flair awards upvote_ratio num_comments archived  poll post_id_parent    redditor_id_parent  body_length  num_chars  num_words  num_sentences  has_special_chars special_chars  num_unique_words  avg_word_length                                         clean_body\n",
       "0  hpao0jn  rknr7b  changemyview  t3_rknr7b       hw76x  2021-12-20 15:10:36+00:00  >Why should I stop flying when cruise ships ar...   {\"2024-11-01T13:01:45\":807}   False     NaN          rknr7b        1.0   NaN  NaN       NaN         NaN   NaN    NaN          NaN          NaN      NaN   NaN         rknr7b  suspended:British231          718        718        125              6               True        ,>#;&%                94         4.656000  [Why should I stop flying when cruise ships ar...\n",
       "1  hpanpbe  rknr7b  changemyview  t3_rknr7b     tz0epq1  2021-12-20 15:07:53+00:00  Why shouldn’t I toss my litter on the ground w...   {\"2024-11-01T13:01:45\":257}   False     NaN          rknr7b        0.0   NaN  NaN       NaN         NaN   NaN    NaN          NaN          NaN      NaN   NaN         rknr7b  suspended:British231          731        731        133              8               True            ’,                89         4.436090  [Why shouldnt I toss my litter on the ground w...\n",
       "2  hpaqa3x  rknr7b  changemyview  t3_rknr7b       xsbp7  2021-12-20 15:29:23+00:00  This is spite, however, it is misapplied.  The...    {\"2024-11-01T13:01:45\":53}   False     NaN          rknr7b        0.0   NaN  NaN       NaN         NaN   NaN    NaN          NaN          NaN      NaN   NaN         rknr7b  suspended:British231          605        605        103              7               True            ,'                65         4.786408  [This is spite however it is misapplied., The ...\n",
       "3  hpb48rk  rknr7b  changemyview  t3_rknr7b    4ena4pzw  2021-12-20 17:13:45+00:00  >Why should I stop using my car and pay multip...    {\"2024-11-01T13:01:46\":61}   False     NaN          rknr7b        0.0   NaN  NaN       NaN         NaN   NaN    NaN          NaN          NaN      NaN   NaN         rknr7b  suspended:British231         1990       1990        305             21               True  )]*(,[>:'/-\"               207         5.485246  [Why should I stop using my car and pay multip...\n",
       "4  hpamqqh  rknr7b  changemyview  t3_rknr7b    d39pn2pj  2021-12-20 14:59:36+00:00  1. If everyone thinks as you do, then change i...  {\"2024-11-01T13:01:46\":1590}   False     NaN          rknr7b        0.0   NaN  NaN       NaN         NaN   NaN    NaN          NaN          NaN      NaN   NaN         rknr7b  suspended:British231          274        274         48              6               True            *,                45         4.729167  [1., If everyone thinks as you do then change ..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_rknr7b.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#theooooooooooooooo\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'&#\\w+;|\\\\x\\w\\w', '', text)  # Remove HTML entities and unicode hex characters\n",
    "    text = re.sub(r'[^\\w\\s\\.\\?\\!]', '', text)  # Remove special characters except for ., ?, !\n",
    "    text = re.sub(r'(?<=\\w)([.?!])(?=\\w)', r'\\1 ', text)  # Ensure spacing after punctuation\n",
    "    text = text.strip().lower()  # Trim and convert to lowercase\n",
    "    return text\n",
    "\n",
    "# Apply the function\n",
    "cleaned_test_comment = clean_text(test_comment)\n",
    "print(cleaned_test_comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "#theooooooooooooooo\n",
    "\n",
    "#thread_rknr7b['body_clean'] = thread_rknr7b[[\"body\"]].astype({\"body\":\"string\"}).apply(clean_text,axis=1)\n",
    "\n",
    "# Apply the clean_text function to each element in the 'body' column\n",
    "thread_rknr7b['body_clean'] = thread_rknr7b['body'].astype(\"string\").apply(clean_text)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(thread_rknr7b[['body', 'body_clean']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_score_split(cleaned_test_comment, 'knowledge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9960183501243591, 0.9960183501243591, 0.9960183501243591, 0.0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_score_split(thread_rknr7b[\"clean_body\"].iloc[0], 'knowledge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.924030688220228e-07, 5.924030688220228e-07, 5.924030688220228e-07, 0.0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_score_split(thread_rknr7b[\"clean_body\"].iloc[0], 'trust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_score_split(cleaned_test_comment, 'similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_score_split(cleaned_test_comment, 'trust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['post_id', 'link_id', 'subreddit', 'parent_id', 'redditor_id', 'created_at', 'body', 'score', 'edited', 'removed', 'parent_id_clean', 'has_delta', 'title', 'text', 'permalink', 'attachment', 'flair', 'awards', 'upvote_ratio', 'num_comments', 'archived', 'poll', 'post_id_parent', 'redditor_id_parent', 'body_length', 'num_chars', 'num_words', 'num_sentences', 'has_special_chars', 'special_chars', 'num_unique_words', 'avg_word_length', 'clean_body'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display all column names to confirm the cleaned body column's name\n",
    "print(thread_rknr7b.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge Scores Dataframe:\n",
      "                                           clean_body  has_delta  knowledge_mean  knowledge_max  knowledge_min  knowledge_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0        0.996018       0.996018       0.996018            0.0\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0        0.995981       0.995981       0.995981            0.0\n",
      "2  [This is spite however it is misapplied., The ...        0.0        0.996001       0.996001       0.996001            0.0\n",
      "3  [Why should I stop using my car and pay multip...        0.0        0.995805       0.995805       0.995805            0.0\n",
      "4  [1., If everyone thinks as you do then change ...        0.0        0.996049       0.996049       0.996049            0.0\n"
     ]
    }
   ],
   "source": [
    "def compute_knowledge_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['clean_body'], 'knowledge')\n",
    "    return pd.Series([row['clean_body'], row['has_delta'], mean, max_score, min_score, std],\n",
    "                     index=['clean_body', 'has_delta', 'knowledge_mean', 'knowledge_max', 'knowledge_min', 'knowledge_std'])\n",
    "# Dataframe for knowledge scores\n",
    "knowledge_scores_df = thread_rknr7b.apply(compute_knowledge_scores, axis=1)\n",
    "# Display the first few rows of the knowledge scores dataframe\n",
    "print(\"Knowledge Scores Dataframe:\\n\", knowledge_scores_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'body_clean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'body_clean'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m     mean, max_score, min_score, std \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcompute_score_split(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody_clean\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledge\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries([mean, max_score, min_score, std], index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledge_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledge_max\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledge_min\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledge_std\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m thread_rknr7b[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledge_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledge_max\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledge_min\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledge_std\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mthread_rknr7b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_knowledge_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[60], line 2\u001b[0m, in \u001b[0;36mcompute_knowledge_scores\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_knowledge_scores\u001b[39m(row):\n\u001b[1;32m----> 2\u001b[0m     mean, max_score, min_score, std \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcompute_score_split(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbody_clean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledge\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries([mean, max_score, min_score, std], index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledge_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledge_max\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledge_min\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledge_std\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'body_clean'"
     ]
    }
   ],
   "source": [
    "def compute_knowledge_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['body_clean'], 'knowledge')\n",
    "    return pd.Series([mean, max_score, min_score, std], index=['knowledge_mean', 'knowledge_max', 'knowledge_min', 'knowledge_std'])\n",
    "\n",
    "thread_rknr7b[['knowledge_mean', 'knowledge_max', 'knowledge_min', 'knowledge_std']] = thread_rknr7b.apply(compute_knowledge_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['body_clean'], 'similarity')\n",
    "    return pd.Series([mean, max_score, min_score, std], index=['similarity_mean', 'similarity_max', 'similarity_min', 'similarity_std'])\n",
    "\n",
    "thread_rknr7b[['similarity_mean', 'similarity_max', 'similarity_min', 'similarity_std']] = thread_rknr7b.apply(compute_similarity_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trust_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['clean_body'], 'trust')\n",
    "    return pd.Series([row['clean_body'], row['has_delta'], mean, max_score, min_score, std],\n",
    "                     index=['clean_body', 'has_delta', 'trust_mean', 'trust_max', 'trust_min', 'trust_std'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'body_clean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'body_clean'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m     mean, max_score, min_score, std \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcompute_score_split(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody_clean\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries([mean, max_score, min_score, std], index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust_max\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust_min\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust_std\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m thread_rknr7b[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust_max\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust_min\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust_std\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mthread_rknr7b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_trust_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[55], line 2\u001b[0m, in \u001b[0;36mcompute_trust_scores\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_trust_scores\u001b[39m(row):\n\u001b[1;32m----> 2\u001b[0m     mean, max_score, min_score, std \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcompute_score_split(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbody_clean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries([mean, max_score, min_score, std], index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust_max\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust_min\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust_std\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'body_clean'"
     ]
    }
   ],
   "source": [
    "def compute_trust_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['body_clean'], 'trust')\n",
    "    return pd.Series([mean, max_score, min_score, std], index=['trust_mean', 'trust_max', 'trust_min', 'trust_std'])\n",
    "\n",
    "thread_rknr7b[['trust_mean', 'trust_max', 'trust_min', 'trust_std']] = thread_rknr7b.apply(compute_trust_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 20 (2176709530.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[66], line 23\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"Knowledge Scores DataFrame:\\n\", dimension_score_dfs['knowledge'].head())            #1>knowledge\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 20\n"
     ]
    }
   ],
   "source": [
    "# List of all 10 dimensions\n",
    "dimensions = ['knowledge', 'power', 'status', 'trust', 'support', 'romance', \n",
    "              'similarity', 'identity', 'fun', 'conflict']\n",
    "\n",
    "# Function to compute scores for a specific dimension\n",
    "def compute_dimension_scores(row, dimension):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['clean_body'], dimension)\n",
    "    return pd.Series([row['clean_body'], row['has_delta'], mean, max_score, min_score, std],\n",
    "                     index=['clean_body', 'has_delta', f'{dimension}_mean', f'{dimension}_max', \n",
    "                            f'{dimension}_min', f'{dimension}_std'])\n",
    "\n",
    "# Loop over dimensions and compute scores for each, storing results in separate DataFrames\n",
    "dimension_score_dfs = {}  # Dictionary to store DataFrames for each dimension\n",
    "for dim in dimensions:\n",
    "    score_df = thread_rknr7b.apply(lambda row: compute_dimension_scores(row, dim), axis=1)\n",
    "    dimension_score_dfs[dim] = score_df  # Store each dimension's DataFrame\n",
    "    prin()\n",
    "\n",
    "# Example: Display the first few rows of the knowledge scores DataFrame\n",
    "\n",
    "for dim in dimention:\n",
    "    \n",
    "\n",
    "print(\"Knowledge Scores DataFrame:\\n\", dimension_score_dfs['knowledge'].head())            #1>knowledge\n",
    "print(\"trust Scores DataFrame:\\n\", dimension_score_dfs['trust'].head())                #2>trust\n",
    "print(\"similarity Scores DataFrame:\\n\", dimension_score_dfs['similarity'].head())           #3>similarity\n",
    "print(\"status Scores DataFrame:\\n\", dimension_score_dfs['status'].head())               #4>status\n",
    "print(\"support Scores DataFrame:\\n\", dimension_score_dfs['support'].head())              #5>support\n",
    "print(\"power Scores DataFrame:\\n\", dimension_score_dfs['power'].head())                #6>power\n",
    "print(\"identity Scores DataFrame:\\n\", dimension_score_dfs['identity'].head())             #7>identity\n",
    "print(\"conflict Scores DataFrame:\\n\", dimension_score_dfs['conflict'].head())             #8>conflict\n",
    "print(\"fun Scores DataFrame:\\n\", dimension_score_dfs['fun'].head())                  #9>fun                            \n",
    "print(\"romance Scores DataFrame:\\n\", dimension_score_dfs['romance'].head())              #10>romance\n",
    "print(\"*******************end******************************************************************************\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Knowledge Scores DataFrame:\n",
      "                                           clean_body  has_delta  knowledge_mean  knowledge_max  knowledge_min  knowledge_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0        0.996018       0.996018       0.996018            0.0\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0        0.995981       0.995981       0.995981            0.0\n",
      "2  [This is spite however it is misapplied., The ...        0.0        0.996001       0.996001       0.996001            0.0\n",
      "3  [Why should I stop using my car and pay multip...        0.0        0.995805       0.995805       0.995805            0.0\n",
      "4  [1., If everyone thinks as you do then change ...        0.0        0.996049       0.996049       0.996049            0.0\n",
      "\n",
      "Power Scores DataFrame:\n",
      "                                           clean_body  has_delta  power_mean  power_max  power_min  power_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0    0.007783   0.007783   0.007783        0.0\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0    0.037280   0.037280   0.037280        0.0\n",
      "2  [This is spite however it is misapplied., The ...        0.0    0.008251   0.008251   0.008251        0.0\n",
      "3  [Why should I stop using my car and pay multip...        0.0    0.967546   0.967546   0.967546        0.0\n",
      "4  [1., If everyone thinks as you do then change ...        0.0    0.910444   0.910444   0.910444        0.0\n",
      "\n",
      "Status Scores DataFrame:\n",
      "                                           clean_body  has_delta  status_mean  status_max  status_min  status_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0     0.054213    0.054213    0.054213         0.0\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0     0.048565    0.048565    0.048565         0.0\n",
      "2  [This is spite however it is misapplied., The ...        0.0     0.061569    0.061569    0.061569         0.0\n",
      "3  [Why should I stop using my car and pay multip...        0.0     0.087969    0.087969    0.087969         0.0\n",
      "4  [1., If everyone thinks as you do then change ...        0.0     0.063845    0.063845    0.063845         0.0\n",
      "\n",
      "Trust Scores DataFrame:\n",
      "                                           clean_body  has_delta    trust_mean     trust_max     trust_min  trust_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0  5.924031e-07  5.924031e-07  5.924031e-07        0.0\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0  5.917854e-07  5.917854e-07  5.917854e-07        0.0\n",
      "2  [This is spite however it is misapplied., The ...        0.0  5.950457e-07  5.950457e-07  5.950457e-07        0.0\n",
      "3  [Why should I stop using my car and pay multip...        0.0  6.021569e-07  6.021569e-07  6.021569e-07        0.0\n",
      "4  [1., If everyone thinks as you do then change ...        0.0  5.917707e-07  5.917707e-07  5.917707e-07        0.0\n",
      "\n",
      "Support Scores DataFrame:\n",
      "                                           clean_body  has_delta  support_mean  support_max  support_min  support_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0      0.000639     0.000639     0.000639          0.0\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0      0.000674     0.000674     0.000674          0.0\n",
      "2  [This is spite however it is misapplied., The ...        0.0      0.000635     0.000635     0.000635          0.0\n",
      "3  [Why should I stop using my car and pay multip...        0.0      0.000640     0.000640     0.000640          0.0\n",
      "4  [1., If everyone thinks as you do then change ...        0.0      0.015983     0.015983     0.015983          0.0\n",
      "\n",
      "Romance Scores DataFrame:\n",
      "                                           clean_body  has_delta  romance_mean  romance_max  romance_min  romance_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0      0.000028     0.000028     0.000028          0.0\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0      0.000319     0.000319     0.000319          0.0\n",
      "2  [This is spite however it is misapplied., The ...        0.0      0.000012     0.000012     0.000012          0.0\n",
      "3  [Why should I stop using my car and pay multip...        0.0      0.000027     0.000027     0.000027          0.0\n",
      "4  [1., If everyone thinks as you do then change ...        0.0      0.000037     0.000037     0.000037          0.0\n",
      "\n",
      "Similarity Scores DataFrame:\n",
      "                                           clean_body  has_delta  similarity_mean  similarity_max  similarity_min  similarity_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0         0.003357        0.003357        0.003357             0.0\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0         0.003349        0.003349        0.003349             0.0\n",
      "2  [This is spite however it is misapplied., The ...        0.0         0.003440        0.003440        0.003440             0.0\n",
      "3  [Why should I stop using my car and pay multip...        0.0         0.003707        0.003707        0.003707             0.0\n",
      "4  [1., If everyone thinks as you do then change ...        0.0         0.003497        0.003497        0.003497             0.0\n",
      "\n",
      "Identity Scores DataFrame:\n",
      "                                           clean_body  has_delta  identity_mean  identity_max  identity_min  identity_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0       0.389586      0.389586      0.389586           0.0\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0       0.278777      0.278777      0.278777           0.0\n",
      "2  [This is spite however it is misapplied., The ...        0.0       0.394250      0.394250      0.394250           0.0\n",
      "3  [Why should I stop using my car and pay multip...        0.0       0.434561      0.434561      0.434561           0.0\n",
      "4  [1., If everyone thinks as you do then change ...        0.0       0.513454      0.513454      0.513454           0.0\n",
      "\n",
      "Fun Scores DataFrame:\n",
      "                                           clean_body  has_delta  fun_mean   fun_max   fun_min  fun_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0  0.991753  0.991753  0.991753      0.0\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0  0.047202  0.047202  0.047202      0.0\n",
      "2  [This is spite however it is misapplied., The ...        0.0  0.014676  0.014676  0.014676      0.0\n",
      "3  [Why should I stop using my car and pay multip...        0.0  0.333906  0.333906  0.333906      0.0\n",
      "4  [1., If everyone thinks as you do then change ...        0.0  0.024092  0.024092  0.024092      0.0\n",
      "\n",
      "Conflict Scores DataFrame:\n",
      "                                           clean_body  has_delta  conflict_mean  conflict_max  conflict_min  conflict_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0       0.870638      0.870638      0.870638           0.0\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0       0.959390      0.959390      0.959390           0.0\n",
      "2  [This is spite however it is misapplied., The ...        0.0       0.956590      0.956590      0.956590           0.0\n",
      "3  [Why should I stop using my car and pay multip...        0.0       0.948422      0.948422      0.948422           0.0\n",
      "4  [1., If everyone thinks as you do then change ...        0.0       0.367508      0.367508      0.367508           0.0\n",
      "\n",
      "*******************End of All Dimension Scores*******************\n"
     ]
    }
   ],
   "source": [
    "# List of all 10 dimensions\n",
    "dimensions = ['knowledge', 'power', 'status', 'trust', 'support', 'romance', \n",
    "              'similarity', 'identity', 'fun', 'conflict']\n",
    "\n",
    "# Function to compute scores for a specific dimension\n",
    "def compute_dimension_scores(row, dimension):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['clean_body'], dimension)\n",
    "    return pd.Series([row['clean_body'], row['has_delta'], mean, max_score, min_score, std],\n",
    "                     index=['clean_body', 'has_delta', f'{dimension}_mean', f'{dimension}_max', \n",
    "                            f'{dimension}_min', f'{dimension}_std'])\n",
    "\n",
    "# Dictionary to store DataFrames for each dimension\n",
    "dimension_score_dfs = {}\n",
    "\n",
    "# Loop over dimensions, compute scores for each, and print results\n",
    "for dim in dimensions:\n",
    "    score_df = thread_rknr7b.apply(lambda row: compute_dimension_scores(row, dim), axis=1)\n",
    "    dimension_score_dfs[dim] = score_df  # Store each dimension's DataFrame\n",
    "    \n",
    "    # Print each dimension's scores DataFrame head\n",
    "    print(f\"\\n{dim.capitalize()} Scores DataFrame:\\n\", score_df.head())\n",
    "\n",
    "print(\"\\n*******************End of All Dimension Scores*******************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences: 6\n",
      "Knowledge Scores for Each Sentence: [0.9560540914535522, 0.4773605763912201, 0.5703498125076294, 0.9677244424819946, 0.9886143207550049, 0.7865568399429321]\n",
      "Mean Knowledge Score: 0.7911100139220556\n",
      "Max Knowledge Score: 0.9886143207550049\n",
      "Min Knowledge Score: 0.4773605763912201\n",
      "Standard Deviation of Knowledge Scores: 0.20190825630244866\n"
     ]
    }
   ],
   "source": [
    "# Set the first cleaned body in a variable\n",
    "test_std_body1 = thread_rknr7b[\"clean_body\"].iloc[0]\n",
    "\n",
    "\n",
    "# Number of sentences in the cleaned body\n",
    "num_sentences = len(test_std_body1)\n",
    "\n",
    "print(\"Number of Sentences:\", num_sentences)\n",
    "\n",
    "\n",
    "# Initialize a list to store knowledge scores for each sentence\n",
    "knowledge_scores = []\n",
    "\n",
    "# Loop through each sentence in the cleaned body and compute the knowledge score\n",
    "for sentence in test_std_body1:\n",
    "    score = model.compute_score(sentence, 'knowledge')\n",
    "    knowledge_scores.append(score)\n",
    "\n",
    "# Calculate mean, max, min, and standard deviation of the scores\n",
    "mean_score = sum(knowledge_scores) / len(knowledge_scores)\n",
    "max_score = max(knowledge_scores)\n",
    "min_score = min(knowledge_scores)\n",
    "std_dev = (sum((x - mean_score) ** 2 for x in knowledge_scores) / len(knowledge_scores)) ** 0.5\n",
    "\n",
    "# Print the results\n",
    "print(\"Knowledge Scores for Each Sentence:\", knowledge_scores)\n",
    "print(\"Mean Knowledge Score:\", mean_score)\n",
    "print(\"Max Knowledge Score:\", max_score)\n",
    "print(\"Min Knowledge Score:\", min_score)\n",
    "print(\"Standard Deviation of Knowledge Scores:\", std_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Knowledge Scores DataFrame:\n",
      "                                           clean_body  has_delta  knowledge_mean  knowledge_max  knowledge_min  knowledge_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0        0.791110       0.988614       0.477361       0.201908\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0        0.525973       0.984643       0.159015       0.281612\n",
      "2  [This is spite however it is misapplied., The ...        0.0        0.713518       0.912191       0.312158       0.191808\n",
      "3  [Why should I stop using my car and pay multip...        0.0        0.754881       0.993185       0.499752       0.152229\n",
      "4  [1., If everyone thinks as you do then change ...        0.0        0.640120       0.991994       0.455412       0.178709\n",
      "\n",
      "Power Scores DataFrame:\n",
      "                                           clean_body  has_delta  power_mean  power_max  power_min  power_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0    0.229991   0.507562   0.006546   0.158872\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0    0.116547   0.332995   0.010362   0.098480\n",
      "2  [This is spite however it is misapplied., The ...        0.0    0.381293   0.779900   0.037706   0.283581\n",
      "3  [Why should I stop using my car and pay multip...        0.0    0.256238   0.782709   0.004406   0.243482\n",
      "4  [1., If everyone thinks as you do then change ...        0.0    0.434381   0.870869   0.123405   0.254207\n",
      "\n",
      "Status Scores DataFrame:\n",
      "                                           clean_body  has_delta  status_mean  status_max  status_min  status_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0     0.084968    0.106932    0.056322    0.016955\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0     0.137248    0.268270    0.045788    0.068589\n",
      "2  [This is spite however it is misapplied., The ...        0.0     0.170559    0.381088    0.051313    0.110152\n",
      "3  [Why should I stop using my car and pay multip...        0.0     0.177167    0.755687    0.047370    0.159639\n",
      "4  [1., If everyone thinks as you do then change ...        0.0     0.234738    0.374369    0.066281    0.132612\n",
      "\n",
      "Trust Scores DataFrame:\n",
      "                                           clean_body  has_delta  trust_mean  trust_max     trust_min  trust_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0    0.020400   0.106909  5.743027e-07   0.039099\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0    0.145080   0.641178  5.736732e-07   0.232953\n",
      "2  [This is spite however it is misapplied., The ...        0.0    0.368554   0.809887  5.917690e-07   0.305162\n",
      "3  [Why should I stop using my car and pay multip...        0.0    0.182577   0.676405  5.851458e-07   0.236908\n",
      "4  [1., If everyone thinks as you do then change ...        0.0    0.254375   0.375609  5.743668e-07   0.138475\n",
      "\n",
      "Support Scores DataFrame:\n",
      "                                           clean_body  has_delta  support_mean  support_max  support_min  support_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0      0.132942     0.361623     0.010710     0.128805\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0      0.311539     0.726418     0.004370     0.282268\n",
      "2  [This is spite however it is misapplied., The ...        0.0      0.289286     0.535767     0.050342     0.131947\n",
      "3  [Why should I stop using my car and pay multip...        0.0      0.192880     0.451293     0.000787     0.140714\n",
      "4  [1., If everyone thinks as you do then change ...        0.0      0.459523     0.840821     0.025647     0.239665\n",
      "\n",
      "Romance Scores DataFrame:\n",
      "                                           clean_body  has_delta  romance_mean  romance_max  romance_min  romance_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0      0.000169     0.000546     0.000019     0.000207\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0      0.000337     0.002228     0.000031     0.000716\n",
      "2  [This is spite however it is misapplied., The ...        0.0      0.000125     0.000534     0.000013     0.000170\n",
      "3  [Why should I stop using my car and pay multip...        0.0      0.009320     0.142505     0.000010     0.032624\n",
      "4  [1., If everyone thinks as you do then change ...        0.0      0.230328     0.501185     0.000082     0.231053\n",
      "\n",
      "Similarity Scores DataFrame:\n",
      "                                           clean_body  has_delta  similarity_mean  similarity_max  similarity_min  similarity_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0         0.346836        0.738064        0.072136        0.215106\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0         0.332660        0.730364        0.067655        0.230535\n",
      "2  [This is spite however it is misapplied., The ...        0.0         0.342898        0.601167        0.077640        0.172091\n",
      "3  [Why should I stop using my car and pay multip...        0.0         0.363424        0.922018        0.005983        0.201800\n",
      "4  [1., If everyone thinks as you do then change ...        0.0         0.367788        0.461113        0.022699        0.156597\n",
      "\n",
      "Identity Scores DataFrame:\n",
      "                                           clean_body  has_delta  identity_mean  identity_max  identity_min  identity_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0       0.395289      0.571342      0.292119      0.086205\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0       0.384632      0.498003      0.316184      0.071515\n",
      "2  [This is spite however it is misapplied., The ...        0.0       0.502752      0.607945      0.385018      0.066240\n",
      "3  [Why should I stop using my car and pay multip...        0.0       0.471152      0.604643      0.323138      0.078664\n",
      "4  [1., If everyone thinks as you do then change ...        0.0       0.501927      0.574610      0.355901      0.068842\n",
      "\n",
      "Fun Scores DataFrame:\n",
      "                                           clean_body  has_delta  fun_mean   fun_max   fun_min   fun_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0  0.244183  0.990077  0.021079  0.337984\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0  0.134932  0.532142  0.019323  0.165163\n",
      "2  [This is spite however it is misapplied., The ...        0.0  0.088517  0.218752  0.018168  0.079700\n",
      "3  [Why should I stop using my car and pay multip...        0.0  0.151508  0.751196  0.007899  0.198498\n",
      "4  [1., If everyone thinks as you do then change ...        0.0  0.166735  0.264124  0.026350  0.078590\n",
      "\n",
      "Conflict Scores DataFrame:\n",
      "                                           clean_body  has_delta  conflict_mean  conflict_max  conflict_min  conflict_std\n",
      "0  [Why should I stop flying when cruise ships ar...        1.0       0.577442      0.854106      0.078175      0.261202\n",
      "1  [Why shouldnt I toss my litter on the ground w...        0.0       0.564406      0.780599      0.245973      0.179666\n",
      "2  [This is spite however it is misapplied., The ...        0.0       0.655749      0.801086      0.363459      0.151287\n",
      "3  [Why should I stop using my car and pay multip...        0.0       0.529984      0.970444      0.155785      0.252419\n",
      "4  [1., If everyone thinks as you do then change ...        0.0       0.414987      0.479353      0.205113      0.095333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to compute scores for a specific dimension with sentence-level aggregation\n",
    "def compute_sentence_level_scores(row, dimension):\n",
    "    # Get the list of sentences in the body\n",
    "    sentences = row['clean_body']\n",
    "    # Calculate the score for each sentence, handling empty scores\n",
    "    scores = [model.compute_score(sentence, dimension) for sentence in sentences if sentence]\n",
    "    \n",
    "    # Check if scores is not empty to avoid calculation on empty lists\n",
    "    if scores:\n",
    "        mean_score = np.mean(scores)\n",
    "        max_score = np.max(scores)\n",
    "        min_score = np.min(scores)\n",
    "        std_score = np.std(scores)\n",
    "    else:\n",
    "        mean_score, max_score, min_score, std_score = np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    return pd.Series([row['clean_body'], row['has_delta'], mean_score, max_score, min_score, std_score],\n",
    "                     index=['clean_body', 'has_delta', f'{dimension}_mean', f'{dimension}_max', \n",
    "                            f'{dimension}_min', f'{dimension}_std'])\n",
    "\n",
    "# Apply this function for each dimension in the dimensions list\n",
    "dimension_score_dfs = {}\n",
    "\n",
    "for dim in dimensions:\n",
    "    score_df = thread_rknr7b.apply(lambda row: compute_sentence_level_scores(row, dim), axis=1)\n",
    "    dimension_score_dfs[dim] = score_df  # Store each dimension's DataFrame\n",
    "    print(f\"\\n{dim.capitalize()} Scores DataFrame:\\n\", score_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_rknr7b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting 3 dimensions for all posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_posts = pd.read_csv(\"../data/posts_final.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text but keep sentence structure due to sentence-level classification\n",
    "def clean_text(row):\n",
    "    text = str(row[0])\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'[^\\w\\s\\.\\?\\!]', '', text)  # Remove special characters except for ., ?, !\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = text.replace('x200b', '') # Remove x200b\n",
    "    return text\n",
    "\n",
    "cleaned_test_comment = clean_text(test_comment)\n",
    "print(cleaned_test_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_posts['body_clean'] = m_posts[[\"body\"]].astype({\"body\":\"string\"}).apply(clean_text,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_knowledge_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['body_clean'], 'knowledge')\n",
    "    return pd.Series([mean, max_score, min_score, std], index=['knowledge_mean', 'knowledge_max', 'knowledge_min', 'knowledge_std'])\n",
    "\n",
    "m_posts[['knowledge_mean', 'knowledge_max', 'knowledge_min', 'knowledge_std']] = m_posts.apply(compute_knowledge_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['body_clean'], 'similarity')\n",
    "    return pd.Series([mean, max_score, min_score, std], index=['similarity_mean', 'similarity_max', 'similarity_min', 'similarity_std'])\n",
    "\n",
    "m_posts[['similarity_mean', 'similarity_max', 'similarity_min', 'similarity_std']] = m_posts.apply(compute_similarity_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trust_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['body_clean'], 'trust')\n",
    "    return pd.Series([mean, max_score, min_score, std], index=['trust_mean', 'trust_max', 'trust_min', 'trust_std'])\n",
    "\n",
    "m_posts[['trust_mean', 'trust_max', 'trust_min', 'trust_std']] = m_posts.apply(compute_trust_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # examples\n",
    "# sentences = {\n",
    "# 'knowledge' : [\n",
    "#     \"Only a fully trained Jedi Knight, with The Force as his ally, will conquer Vader and his Emperor. If you end your training now, if you choose the quick and easy path, as Vader did, you will become an agent of evil\",\n",
    "#     \"Well, in layman's terms, you use a rotating magnetic field to focus a narrow beam of gravitons; these in turn fold space-time consistent with Weyl tensor dynamics until the space-time curvature becomes infinitely large and you have a singularity\",\n",
    "#     \"Since positronic signatures have only been known to emanate from androids such as myself, it is logical to theorize that there is an android such as myself on Kolarus III\",\n",
    "# ],\n",
    "\n",
    "# 'power' : [\n",
    "#     \"Now if you don't want to be the fifth person ever to die in meta-shock from a planar rift, I suggest you get down behind that desk and don't move until we give you the signal\",\n",
    "#     \"You can ask any price you want, but you must give me those letters \",\n",
    "#     \"Right now you're in no position to ask questions! And your snide remarks...\"\n",
    "# ],\n",
    "\n",
    "# 'status' : [\n",
    "#     \"I want to thank you, sir, for giving me the opportunity to work\",\n",
    "#     \"Frankie, you're a good old man, and you've been loyal to my Father for years...so I hope you can explain what you mean\",\n",
    "#     \"And we drink to her, and we all congratulate her on her wonderful accomplishment during this last year...her great success in A Doll's House!\"\n",
    "# ],\n",
    "\n",
    "# 'trust' : [\n",
    "#     \"I'm trying to tell you – and this is where you have to trust me – but, I think your life might be in real danger\",\n",
    "#     \"Mr. Lebowski is prepared to make a generous offer to you to act as courier once we get instructions for the money\",\n",
    "#     \"Take the Holy Gospels in your hand and swear to tell the whole truth concerning everything you will be asked\"\n",
    "# ],\n",
    "\n",
    "# 'support' : [\n",
    "#     \"I'm sorry, I just feel like... I know I shouldn't ask, I just need some kind of help, I just, I have a deadline tomorrow\",\n",
    "#     \"Look, Dave, I know that you're sincere and that you're trying to do a competent job, and that you're trying to be helpful, but I can assure the problem is with the AO-units, and with your test gear\",\n",
    "#     \"Well... listen, if you need any help, you know, back up, call me, OK?\"\n",
    "# ],\n",
    "\n",
    "# 'romance' : [\n",
    "#     \"I'm going to marry the woman I love\",\n",
    "#     \"If you are truly wild at heart, you'll fight for your dreams... Don’t turn away from love, Sailor \",\n",
    "#     \"You admit to me you do not love your fiance?\"\n",
    "# ],\n",
    "\n",
    "# 'identity' : [\n",
    "#     \"Hey, I know what I'm talkin' about, black women ain't the same as white women \",\n",
    "#     \"That's how it was in the old world, Pop, but this is not Sicily\",\n",
    "#     \"But, as you are so fond of observing, Doctor, I'm not human\"\n",
    "# ],\n",
    "\n",
    "# 'fun' : [\n",
    "#     \"It’s just funny...who needs a serial psycho in the woods with a chainsaw when we have ourselves\",\n",
    "#     \"I do enjoy playing bingo, if you'd like to join me for a game tomorrow night at church you’re welcome to\",\n",
    "#     \"Oh, I'm sure it’s a lot of fun, 'cause the Incas did it, you know, and-and they-they-they were a million laughs\"\n",
    "# ],\n",
    "\n",
    "# 'conflict' : [\n",
    "#     \"Forgive me for askin', son, and I don’t mean to belabor the obvious, but why is it that you’ve got your head so far up your own ass?\",\n",
    "#     \"If you're lying to me you poor excuse for a human being, I'm gonna blow your brains all over this car\",\n",
    "#     \"I couldn't give a shit if you believe me or not, and frankly I'm too tired to prove it to you\"\n",
    "# ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for dim in sentences:\n",
    "#     print(f' === {dim.upper()} ===')\n",
    "#     for s in sentences[dim]:\n",
    "#         score = model.compute_score(s, dim)\n",
    "#         print (f'{s} -- {dim}={score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
