{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mitra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tendims\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded word embeddings from ./embeddings\\glove/glove.42B.300d.wv!\n",
      "Vocab size: 1917494\n",
      "Loaded word embeddings from ./embeddings\\word2vec/GoogleNews-vectors-negative300.wv!\n",
      "Vocab size: 3000000\n",
      "Loaded word embeddings from ./embeddings\\fasttext/wiki-news-300d-1M-subword.wv!\n",
      "Vocab size: 999994\n",
      "['support', 'knowledge', 'conflict', 'power', 'similarity', 'fun', 'status', 'trust', 'identity', 'romance']\n"
     ]
    }
   ],
   "source": [
    "model = tendims.TenDimensionsClassifier(is_cuda=False, models_dir = './models/lstm_trained_models', \n",
    "                                        embeddings_dir='./embeddings')\n",
    "dimensions = model.dimensions_list\n",
    "print(dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence-level classification\n",
    "\n",
    "The classifier was trained on individual sentences. Although the classifier accepts text of any length, we recommend to compute the scores sentence-by-sentence. The function compute_score_split does that for you and returns the maximum and average values. When using the maximum, please consider that the longer the text, the higher the likelihood to get a larger maximum value. So, if you use the maximum, be sure to account for text length in you analysis (i.e. a high maximum score on a text of 10 words is not comparable with the same value on a text of 100 words). You can always split the sentences yourself and aggregate sentence-level values as you deem appropriate.\n",
    "\n",
    "Score distribution\n",
    "\n",
    "The classifier returns confidence scores in the range [0,1]. This number is proportional to the likelihood of the text containing the selected dimension. Depending on the input data and on the aggregation performed, the empirical distributions of the confidence score may differ across dimensions (may be bell-shaped, skewed, bi-modal, etc.). For this reason, binarizing the scores based on a fixed threshold might not be the best approach. An approch that proved effective is to binarize based on a high percentile (e.g., 75th or 85th percentiles) computed on your empirical distribution of scores.\n",
    "\n",
    "Directionality\n",
    "\n",
    "The classifier was trained to identify expressions that \"convey\" dimension D from the speaker to the listener. For example, in the case of the dimension support, the classifier is supposed to find expressions indicating that the speaker is offering some support to the lister. In practice, this directionality is not guaranteed, and the classifier picks up different types of verbal expressions of the social dimensions. For example, \"I am willing to help you, whatever you need\" and \"Clara is willing to help George, whatever he needs\" have both relatively high scores for the dimension support (0.86 and 0.75, respectively), but only the first one is an expression of the speaker offering support. To more strongly enforce directionality, and approach that proved effective is to consider only sentences containing second-person pronouns.\n",
    "\n",
    "Errors\n",
    "\n",
    "Be aware that the classifier was trained mostly on Reddit data. It can be used on any piece of text but you should expect some performance drop when used on textual data with very different style or distribution of words (e.g., Twitter). Last, as everything in life, the classifications made by this tool are not perfect, but given eough data you'll be able to see interesting and meaningful trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "model.compute_score_split('Hello, my name is Mike. I am willing to help you, whatever you need.', dimensions='support')\n",
    "# (np.mean(scores), np.max(scores), np.min(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing individual threads and comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & read the data\n",
    "thread_rknr7b = pd.read_csv(\"../data/threads/rknr7b.csv\")\n",
    "thread_rknr7b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all column names to confirm the cleaned body column's name\n",
    "print(thread_rknr7b.columns)\n",
    "\n",
    "# Get the number of rows in the DataFrame\n",
    "num_rows = thread_rknr7b.shape[0]\n",
    "print(\"Number of rows in the DataFrame:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the full content of the 'body' for the first row to avoid truncation\n",
    "\n",
    "# Set display option to show full text in columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"*******1\\nFull Body Text of the First Entry:\\n\", thread_rknr7b.loc[0, \"body\"])\n",
    "print(\"*******3\\nFull Body Text of the third Entry:\\n\", thread_rknr7b.loc[3, \"body\"])\n",
    "print(\"*******5\\nFull Body Text of the fifth Entry:\\n\", thread_rknr7b.loc[5, \"body\"])\n",
    "\n",
    "# Check the data type of the 'body' column\n",
    "print(\"\\n *******\\nData type of 'body' column:\\n\", thread_rknr7b[\"body\"].dtype)\n",
    "\n",
    "# Fill NaN values in 'body' with an empty string before calculating the length\n",
    "thread_rknr7b[\"body\"] = thread_rknr7b[\"body\"].fillna(\"\")\n",
    "\n",
    "# Calculate the length of the text in 'body' for each entry and add it as a new column\n",
    "thread_rknr7b[\"body_length\"] = thread_rknr7b[\"body\"].apply(len)\n",
    "\n",
    "\n",
    "# Show summary statistics for the body lengths\n",
    "print(\"\\n *******\\nSummary of 'body' lengths:\\n\", thread_rknr7b[\"body_length\"].describe())\n",
    "\n",
    "# Display the first few rows to inspect the 'body_length' column\n",
    "print(\"\\n******* \\nSample rows with 'body' text and its length:\\n\")\n",
    "print(thread_rknr7b[[\"body\", \"body_length\"]].head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format 1> analyze_text\n",
    "# Define a function to calculate additional metrics and check for special characters\n",
    "def analyze_text(text):\n",
    "    num_chars = len(text) if isinstance(text, str) else 0\n",
    "    num_words = len(text.split()) if isinstance(text, str) else 0\n",
    "    num_sentences = len(re.split(r'[.!?]', text)) - 1 if isinstance(text, str) else 0\n",
    "    has_special_chars = bool(re.search(r'[\\[\\]\\{\\}\\*\\&]', text)) if isinstance(text, str) else False  # Check for special characters\n",
    "    return pd.Series({\n",
    "        \"num_chars\": num_chars,\n",
    "        \"num_words\": num_words,\n",
    "        \"num_sentences\": num_sentences,\n",
    "        \"has_special_chars\": has_special_chars\n",
    "    })\n",
    "\n",
    "# Apply the function to each row in 'body' and store results in new columns\n",
    "thread_rknr7b[[\"num_chars\", \"num_words\", \"num_sentences\", \"has_special_chars\"]] = thread_rknr7b[\"body\"].apply(analyze_text)\n",
    "\n",
    "# Display the extracted metrics table without the 'body' column\n",
    "print(thread_rknr7b[[\"num_chars\", \"num_words\", \"num_sentences\", \"has_special_chars\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format 2> analyze_text\n",
    "# Define the function to analyze text\n",
    "def analyze_text_with_special_chars(text):\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        special_chars = re.findall(r'[^\\w\\s\\.\\?\\!]', text)  # Find characters that aren't alphanumeric, space, ., ?, !\n",
    "        has_special_chars = len(special_chars) > 0\n",
    "        return pd.Series({\n",
    "            \"num_chars\": len(text),\n",
    "            \"num_words\": len(text.split()),\n",
    "            \"num_sentences\": len(re.split(r'[.!?]', text)) - 1,\n",
    "            \"has_special_chars\": has_special_chars,\n",
    "            \"special_chars\": ''.join(set(special_chars))  # Unique special characters\n",
    "        })\n",
    "    else:\n",
    "        return pd.Series({\n",
    "            \"num_chars\": 0,\n",
    "            \"num_words\": 0,\n",
    "            \"num_sentences\": 0,\n",
    "            \"has_special_chars\": False,\n",
    "            \"special_chars\": \"\"\n",
    "        })\n",
    "    \n",
    "# Display other statistical features if needed\n",
    "print(\"\\nAdditional Features:\")\n",
    "print(\"Number of Words in 'body':\", len(body_text.split()))\n",
    "print(\"Number of Unique Words in 'body':\", len(set(body_text.split())))\n",
    "print(\"Average Word Length in 'body':\", sum(len(word) for word in body_text.split()) / len(body_text.split()))\n",
    "\n",
    "# Apply the function to each row in 'body' and store results in new columns\n",
    "thread_rknr7b[[\"num_chars\", \"num_words\", \"num_sentences\", \"has_special_chars\", \"special_chars\"]] = thread_rknr7b[\"body\"].apply(analyze_text_with_special_chars)\n",
    "\n",
    "# Display the metrics without the body content\n",
    "print(thread_rknr7b[[\"num_chars\", \"num_words\", \"num_sentences\", \"has_special_chars\", \"special_chars\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format 3> analyze_text\n",
    "\n",
    "# Define the function to analyze text\n",
    "def analyze_text_with_special_chars(text):\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        # Find special characters that aren't alphanumeric, spaces, ., ?, !\n",
    "        special_chars = re.findall(r'[^\\w\\s\\.\\?\\!]', text)\n",
    "        has_special_chars = len(special_chars) > 0\n",
    "        words = text.split()\n",
    "        \n",
    "        # Calculate unique words and average word length\n",
    "        num_unique_words = len(set(words))\n",
    "        avg_word_length = sum(len(word) for word in words) / len(words) if words else 0\n",
    "\n",
    "        return pd.Series({\n",
    "            \"num_chars\": len(text),\n",
    "            \"num_words\": len(words),\n",
    "            \"num_sentences\": len(re.split(r'[.!?]', text)) - 1,\n",
    "            \"has_special_chars\": has_special_chars,\n",
    "            \"special_chars\": ''.join(set(special_chars)),  # Unique special characters\n",
    "            \"num_unique_words\": num_unique_words,\n",
    "            \"avg_word_length\": avg_word_length\n",
    "        })\n",
    "    else:\n",
    "        # Handle non-string entries\n",
    "        return pd.Series({\n",
    "            \"num_chars\": 0,\n",
    "            \"num_words\": 0,\n",
    "            \"num_sentences\": 0,\n",
    "            \"has_special_chars\": False,\n",
    "            \"special_chars\": \"\",\n",
    "            \"num_unique_words\": 0,\n",
    "            \"avg_word_length\": 0\n",
    "        })\n",
    "\n",
    "# Apply the function to each row in 'body' and store results in new columns\n",
    "thread_rknr7b[[\"num_chars\", \"num_words\", \"num_sentences\", \"has_special_chars\", \"special_chars\", \n",
    "               \"num_unique_words\", \"avg_word_length\"]] = thread_rknr7b[\"body\"].apply(analyze_text_with_special_chars)\n",
    "\n",
    "# Display the metrics without the body content\n",
    "print(thread_rknr7b[[\"num_chars\", \"num_words\", \"num_sentences\", \"has_special_chars\", \n",
    "                     \"special_chars\", \"num_unique_words\", \"avg_word_length\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's fisrt work on the first bodey now >   body[0] is uor sample :\n",
    "# Display the full content of the 'body' column for the first row\n",
    "body_text1 = thread_rknr7b.loc[0, \"body\"]  # Access the full text of the first entry\n",
    "print(body_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of the 'body' content\n",
    "print(\"Type of 'body':\", type(body_text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length\n",
    "print(\"Length of 'body':\", len(body_text1))\n",
    "\n",
    "# Display the last 100 characters to confirm if there’s more to the text\n",
    "print(\"Last part of text:\", body_text1[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'has_delta' is 1\n",
    "delta_rows = thread_rknr7b[thread_rknr7b['has_delta'] == 1]\n",
    "\n",
    "delta_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count rows with has_delta as 0 and 1\n",
    "delta_counts= thread_rknr7b['has_delta'].value_counts()\n",
    "print(delta_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where has_delta is 1 and display the first few\n",
    "delta_rows_sample = thread_rknr7b[thread_rknr7b['has_delta'] == 1].head(4)\n",
    "\n",
    "# Display the 'body' column and other relevant columns if needed\n",
    "delta_rows_sample[['body', 'has_delta']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_with_delta = thread_rknr7b[thread_rknr7b['has_delta'] == 1]\n",
    "posts_with_delta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comment = posts_with_delta.iloc[0]['body']\n",
    "print(test_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean_and_split_text(text):\n",
    "    # Remove special characters except ., ?, !\n",
    "    text = re.sub(r'[^\\w\\s\\.\\?\\!]', '', text)  \n",
    "    \n",
    "    # Split into sentences based on punctuation marks and clean up spaces\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    \n",
    "    # Remove empty sentences and ensure they are properly formatted\n",
    "    clean_sentences = [sentence.strip() for sentence in sentences if sentence]\n",
    "    \n",
    "    return clean_sentences\n",
    "\n",
    "# Apply the cleaning function to the 'body' column and add the result as a new column\n",
    "thread_rknr7b[\"clean_body\"] = thread_rknr7b[\"body\"].apply(clean_and_split_text)\n",
    "\n",
    "# Display the cleaned and split body\n",
    "print(thread_rknr7b[[\"body\", \"clean_body\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_split_text_improved(text):\n",
    "    # Remove special characters except ., ?, !\n",
    "    text = re.sub(r'&#x200B;|\\n|\\t', ' ', text)  # Removes specific placeholders and newline characters\n",
    "    text = re.sub(r'[^\\w\\s\\.\\?\\!]', '', text)  # Removes all other special characters except ., ?, !\n",
    "    \n",
    "    # Split into sentences based on punctuation marks and clean up spaces\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    \n",
    "    # Remove empty sentences and ensure they are properly formatted\n",
    "    clean_sentences = [sentence.strip() for sentence in sentences if sentence]\n",
    "    \n",
    "    return clean_sentences\n",
    "\n",
    "# Apply the improved cleaning function to the 'body' column\n",
    "thread_rknr7b[\"clean_body\"] = thread_rknr7b[\"body\"].apply(clean_and_split_text_improved)\n",
    "\n",
    "# Display the comparison of the first entry\n",
    "print(\"Original Body:\\n\", thread_rknr7b[\"body\"].iloc[0])\n",
    "print(\"\\nCleaned and Split Sentences:\\n\", thread_rknr7b[\"clean_body\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def clean_and_split_text_improved(text):\n",
    "    # Remove special characters except ., ?, !\n",
    "    text = re.sub(r'&#x200B;|\\n|\\t', ' ', text)  # Removes specific placeholders and newline characters\n",
    "    text = re.sub(r'[^\\w\\s\\.\\?\\!]', '', text)  # Removes all other special characters except ., ?, !\n",
    "    \n",
    "    # Split into sentences based on punctuation marks and clean up spaces\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    \n",
    "    # Remove empty sentences and ensure they are properly formatted\n",
    "    clean_sentences = [sentence.strip() for sentence in sentences if sentence]\n",
    "    \n",
    "    return clean_sentences\n",
    "\n",
    "# Apply the improved cleaning function to the 'body' column\n",
    "thread_rknr7b[\"clean_body\"] = thread_rknr7b[\"body\"].apply(clean_and_split_text_improved)\n",
    "\n",
    "# Display the comparison of the first entry\n",
    "print(\"Original Body:\\n\", thread_rknr7b[\"body\"].iloc[0])\n",
    "print(\"\\nCleaned and Split Sentences:\\n\", thread_rknr7b[\"clean_body\"].iloc[0])\n",
    "'''\n",
    "\n",
    "def advanced_clean_and_split_text(text):\n",
    "    text = re.sub(r'&#x200B;|\\n|\\t', ' ', text)  # Remove specific placeholders, newline characters, and tabs\n",
    "    text = re.sub(r'http\\S+', '', text)   # Remove URLs\n",
    "    #text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)  # Insert spaces where lowercase and uppercase letters are merged\n",
    "    #text = re.sub(r\"\\bIm\\b\", \"I'm\", text) # Handle common contractions (expand or correct them)\n",
    "    #text = re.sub(r\"\\bIts\\b\", \"It's\", text) # Handle common contractions (expand or correct them)\n",
    "    #text = re.sub(r\"\\bDont\\b\", \"Don't\", text)  # Handle common contractions (expand or correct them)\n",
    "    text = re.sub(r'[^\\w\\s\\.\\?\\!]', '', text)  # Remove other special characters except ., ?, !\n",
    "    \n",
    "    # Split into sentences based on punctuation marks\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    # Clean up spaces and filter out any empty sentences\n",
    "    clean_sentences = [sentence.strip() for sentence in sentences if sentence]\n",
    "    return clean_sentences\n",
    "\n",
    "# Apply this new cleaning function to the 'body' column\n",
    "thread_rknr7b[\"clean_body\"] = thread_rknr7b[\"body\"].apply(advanced_clean_and_split_text)\n",
    "\n",
    "# Display the comparison of the third entry to check improvements\n",
    "print(\"Original Body:\\n\", thread_rknr7b[\"body\"].iloc[3])\n",
    "print(\"\\nAdvanced Cleaned and Split Sentences:\\n\", thread_rknr7b[\"clean_body\"].iloc[3])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_rknr7b.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#theooooooooooooooo\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'&#\\w+;|\\\\x\\w\\w', '', text)  # Remove HTML entities and unicode hex characters\n",
    "    text = re.sub(r'[^\\w\\s\\.\\?\\!]', '', text)  # Remove special characters except for ., ?, !\n",
    "    text = re.sub(r'(?<=\\w)([.?!])(?=\\w)', r'\\1 ', text)  # Ensure spacing after punctuation\n",
    "    text = text.strip().lower()  # Trim and convert to lowercase\n",
    "    return text\n",
    "\n",
    "# Apply the function\n",
    "cleaned_test_comment = clean_text(test_comment)\n",
    "print(cleaned_test_comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "#theooooooooooooooo\n",
    "\n",
    "#thread_rknr7b['body_clean'] = thread_rknr7b[[\"body\"]].astype({\"body\":\"string\"}).apply(clean_text,axis=1)\n",
    "\n",
    "# Apply the clean_text function to each element in the 'body' column\n",
    "thread_rknr7b['body_clean'] = thread_rknr7b['body'].astype(\"string\").apply(clean_text)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(thread_rknr7b[['body', 'body_clean']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_score_split(cleaned_test_comment, 'knowledge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_score_split(thread_rknr7b[\"clean_body\"].iloc[0], 'knowledge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_score_split(thread_rknr7b[\"clean_body\"].iloc[0], 'trust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_score_split(cleaned_test_comment, 'similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_score_split(cleaned_test_comment, 'trust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all column names to confirm the cleaned body column's name\n",
    "print(thread_rknr7b.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_knowledge_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['clean_body'], 'knowledge')\n",
    "    return pd.Series([row['clean_body'], row['has_delta'], mean, max_score, min_score, std],\n",
    "                     index=['clean_body', 'has_delta', 'knowledge_mean', 'knowledge_max', 'knowledge_min', 'knowledge_std'])\n",
    "# Dataframe for knowledge scores\n",
    "knowledge_scores_df = thread_rknr7b.apply(compute_knowledge_scores, axis=1)\n",
    "# Display the first few rows of the knowledge scores dataframe\n",
    "print(\"Knowledge Scores Dataframe:\\n\", knowledge_scores_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_knowledge_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['body_clean'], 'knowledge')\n",
    "    return pd.Series([mean, max_score, min_score, std], index=['knowledge_mean', 'knowledge_max', 'knowledge_min', 'knowledge_std'])\n",
    "\n",
    "thread_rknr7b[['knowledge_mean', 'knowledge_max', 'knowledge_min', 'knowledge_std']] = thread_rknr7b.apply(compute_knowledge_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['body_clean'], 'similarity')\n",
    "    return pd.Series([mean, max_score, min_score, std], index=['similarity_mean', 'similarity_max', 'similarity_min', 'similarity_std'])\n",
    "\n",
    "thread_rknr7b[['similarity_mean', 'similarity_max', 'similarity_min', 'similarity_std']] = thread_rknr7b.apply(compute_similarity_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trust_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['clean_body'], 'trust')\n",
    "    return pd.Series([row['clean_body'], row['has_delta'], mean, max_score, min_score, std],\n",
    "                     index=['clean_body', 'has_delta', 'trust_mean', 'trust_max', 'trust_min', 'trust_std'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trust_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['body_clean'], 'trust')\n",
    "    return pd.Series([mean, max_score, min_score, std], index=['trust_mean', 'trust_max', 'trust_min', 'trust_std'])\n",
    "\n",
    "thread_rknr7b[['trust_mean', 'trust_max', 'trust_min', 'trust_std']] = thread_rknr7b.apply(compute_trust_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all 10 dimensions\n",
    "dimensions = ['knowledge', 'power', 'status', 'trust', 'support', 'romance', \n",
    "              'similarity', 'identity', 'fun', 'conflict']\n",
    "\n",
    "# Function to compute scores for a specific dimension\n",
    "def compute_dimension_scores(row, dimension):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['clean_body'], dimension)\n",
    "    return pd.Series([row['clean_body'], row['has_delta'], mean, max_score, min_score, std],\n",
    "                     index=['clean_body', 'has_delta', f'{dimension}_mean', f'{dimension}_max', \n",
    "                            f'{dimension}_min', f'{dimension}_std'])\n",
    "\n",
    "# Loop over dimensions and compute scores for each, storing results in separate DataFrames\n",
    "dimension_score_dfs = {}  # Dictionary to store DataFrames for each dimension\n",
    "for dim in dimensions:\n",
    "    score_df = thread_rknr7b.apply(lambda row: compute_dimension_scores(row, dim), axis=1)\n",
    "    dimension_score_dfs[dim] = score_df  # Store each dimension's DataFrame\n",
    "    \n",
    "\n",
    "# Example: Display the first few rows of the knowledge scores DataFrame\n",
    "\n",
    "print(\"Knowledge Scores DataFrame:\\n\", dimension_score_dfs['knowledge'].head())            #1>knowledge\n",
    "print(\"trust Scores DataFrame:\\n\", dimension_score_dfs['trust'].head())                #2>trust\n",
    "print(\"similarity Scores DataFrame:\\n\", dimension_score_dfs['similarity'].head())           #3>similarity\n",
    "print(\"status Scores DataFrame:\\n\", dimension_score_dfs['status'].head())               #4>status\n",
    "print(\"support Scores DataFrame:\\n\", dimension_score_dfs['support'].head())              #5>support\n",
    "print(\"power Scores DataFrame:\\n\", dimension_score_dfs['power'].head())                #6>power\n",
    "print(\"identity Scores DataFrame:\\n\", dimension_score_dfs['identity'].head())             #7>identity\n",
    "print(\"conflict Scores DataFrame:\\n\", dimension_score_dfs['conflict'].head())             #8>conflict\n",
    "print(\"fun Scores DataFrame:\\n\", dimension_score_dfs['fun'].head())                  #9>fun                            \n",
    "print(\"romance Scores DataFrame:\\n\", dimension_score_dfs['romance'].head())              #10>romance\n",
    "print(\"*******************end******************************************************************************\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all 10 dimensions\n",
    "dimensions = ['knowledge', 'power', 'status', 'trust', 'support', 'romance', \n",
    "              'similarity', 'identity', 'fun', 'conflict']\n",
    "\n",
    "# Function to compute scores for a specific dimension\n",
    "def compute_dimension_scores(row, dimension):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['clean_body'], dimension)\n",
    "    return pd.Series([row['clean_body'], row['has_delta'], mean, max_score, min_score, std],\n",
    "                     index=['clean_body', 'has_delta', f'{dimension}_mean', f'{dimension}_max', \n",
    "                            f'{dimension}_min', f'{dimension}_std'])\n",
    "\n",
    "# Dictionary to store DataFrames for each dimension\n",
    "dimension_score_dfs = {}\n",
    "\n",
    "# Loop over dimensions, compute scores for each, and print results\n",
    "for dim in dimensions:\n",
    "    score_df = thread_rknr7b.apply(lambda row: compute_dimension_scores(row, dim), axis=1)\n",
    "    dimension_score_dfs[dim] = score_df  # Store each dimension's DataFrame\n",
    "    \n",
    "    # Print each dimension's scores DataFrame head\n",
    "    print(f\"\\n{dim.capitalize()} Scores DataFrame:\\n\", score_df.head())\n",
    "\n",
    "print(\"\\n*******************End of All Dimension Scores*******************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s= \"Only a fully trained Jedi Knight, with The Force as his ally, will conquer Vader and his Emperor. If you end your training now, if you choose the quick and easy path, as Vader did, you will become an agent of evil\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from your_module_path import TenDimensionsClassifier  # Replace with the actual path to the TenDimensionsClassifier class\n",
    "\n",
    "# Initialize the classifier with your specified models and embeddings directories\n",
    "classifier = TenDimensionsClassifier(\n",
    "    models_dir='./models/lstm_trained_models',  # Path where the models are stored\n",
    "    embeddings_dir='./embeddings',              # Path where the embeddings are stored\n",
    "    is_cuda=False                               # Set to True if using GPU\n",
    ")\n",
    "\n",
    "# Function to compute all ten dimensions' scores for each row's clean_body\n",
    "def compute_all_dimensions_scores(row):\n",
    "    text = row['clean_body']  # Access the cleaned body of text in each row\n",
    "    scores_dict = {}\n",
    "    \n",
    "    # Iterate over each dimension to calculate the scores\n",
    "    for dimension in classifier.dimensions_list:\n",
    "        # Calculate the mean, max, min, and std for each dimension at the sentence level\n",
    "        mean, max_score, min_score, std = classifier.compute_score_split(text, dimension)\n",
    "        \n",
    "        # Store the results in a dictionary with clear naming\n",
    "        scores_dict.update({\n",
    "            f\"{dimension}_mean\": mean,\n",
    "            f\"{dimension}_max\": max_score,\n",
    "            f\"{dimension}_min\": min_score,\n",
    "            f\"{dimension}_std\": std\n",
    "        })\n",
    "        \n",
    "    return pd.Series(scores_dict)\n",
    "\n",
    "# Apply the function to each row in your dataframe to get dimension scores\n",
    "dimension_scores_df = thread_rknr7b.apply(compute_all_dimensions_scores, axis=1)\n",
    "\n",
    "# Combine the new dimension scores with the original dataframe\n",
    "final_df = pd.concat([thread_rknr7b, dimension_scores_df], axis=1)\n",
    "\n",
    "# Display the final dataframe with dimension scores\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tendimensions import DimensionClassifier  # Adjust import if the actual name differs\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the model with chosen embedding type\n",
    "embedding_path = 'embeddings/glove/glove.42B.300d.wv'  # Replace with actual path to your embeddings\n",
    "model = DimensionClassifier(embedding_type='glove', embedding_path=embedding_path)\n",
    "\n",
    "# Assuming `thread_rknr7b` is your dataset\n",
    "# Apply cleaning function to split the 'body' into sentences and save it in 'clean_body'\n",
    "def clean_and_split_text(text):\n",
    "    # Replace this with your cleaning function\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    return [sentence.strip() for sentence in sentences if sentence]\n",
    "\n",
    "thread_rknr7b[\"clean_body\"] = thread_rknr7b[\"body\"].apply(clean_and_split_text)\n",
    "\n",
    "# Function to calculate scores for a single dimension\n",
    "def compute_dimension_scores(row, dimension):\n",
    "    scores = [model.compute_score_split(sentence, dimension) for sentence in row['clean_body']]\n",
    "    means = [score[0] for score in scores]\n",
    "    max_scores = [score[1] for score in scores]\n",
    "    min_scores = [score[2] for score in scores]\n",
    "    std_devs = [score[3] for score in scores]\n",
    "    return pd.Series({\n",
    "        f'{dimension}_mean': np.mean(means),\n",
    "        f'{dimension}_max': np.max(max_scores),\n",
    "        f'{dimension}_min': np.min(min_scores),\n",
    "        f'{dimension}_std': np.std(means)\n",
    "    })\n",
    "\n",
    "# Calculate scores for each dimension\n",
    "dimensions = ['knowledge', 'trust', 'support', 'similarity', 'power', 'status', 'identity', 'fun', 'romance', 'conflict']\n",
    "for dim in dimensions:\n",
    "    # Apply the scoring function to each row\n",
    "    score_df = thread_rknr7b.apply(lambda row: compute_dimension_scores(row, dim), axis=1)\n",
    "    # Concatenate the resulting scores to your main DataFrame\n",
    "    thread_rknr7b = pd.concat([thread_rknr7b, score_df], axis=1)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(thread_rknr7b.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the first cleaned body in a variable\n",
    "test_std_body1 = thread_rknr7b[\"clean_body\"].iloc[0]\n",
    "\n",
    "\n",
    "# Number of sentences in the cleaned body\n",
    "num_sentences = len(test_std_body1)\n",
    "\n",
    "print(\"Number of Sentences:\", num_sentences)\n",
    "\n",
    "\n",
    "# Initialize a list to store knowledge scores for each sentence\n",
    "knowledge_scores = []\n",
    "\n",
    "# Loop through each sentence in the cleaned body and compute the knowledge score\n",
    "for sentence in test_std_body1:\n",
    "    score = model.compute_score(sentence, 'knowledge')\n",
    "    knowledge_scores.append(score)\n",
    "\n",
    "# Calculate mean, max, min, and standard deviation of the scores\n",
    "mean_score = sum(knowledge_scores) / len(knowledge_scores)\n",
    "max_score = max(knowledge_scores)\n",
    "min_score = min(knowledge_scores)\n",
    "std_dev = (sum((x - mean_score) ** 2 for x in knowledge_scores) / len(knowledge_scores)) ** 0.5\n",
    "\n",
    "# Print the results\n",
    "print(\"Knowledge Scores for Each Sentence:\", knowledge_scores)\n",
    "print(\"Mean Knowledge Score:\", mean_score)\n",
    "print(\"Max Knowledge Score:\", max_score)\n",
    "print(\"Min Knowledge Score:\", min_score)\n",
    "print(\"Standard Deviation of Knowledge Scores:\", std_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to compute scores for a specific dimension with sentence-level aggregation\n",
    "def compute_sentence_level_scores(row, dimension):\n",
    "    # Get the list of sentences in the body\n",
    "    sentences = row['clean_body']\n",
    "    # Calculate the score for each sentence, handling empty scores\n",
    "    scores = [model.compute_score(sentence, dimension) for sentence in sentences if sentence]\n",
    "    \n",
    "    # Check if scores is not empty to avoid calculation on empty lists\n",
    "    if scores:\n",
    "        mean_score = np.mean(scores)\n",
    "        max_score = np.max(scores)\n",
    "        min_score = np.min(scores)\n",
    "        std_score = np.std(scores)\n",
    "    else:\n",
    "        mean_score, max_score, min_score, std_score = np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    return pd.Series([row['clean_body'], row['has_delta'], mean_score, max_score, min_score, std_score],\n",
    "                     index=['clean_body', 'has_delta', f'{dimension}_mean', f'{dimension}_max', \n",
    "                            f'{dimension}_min', f'{dimension}_std'])\n",
    "\n",
    "# Apply this function for each dimension in the dimensions list\n",
    "dimension_score_dfs = {}\n",
    "\n",
    "for dim in dimensions:\n",
    "    score_df = thread_rknr7b.apply(lambda row: compute_sentence_level_scores(row, dim), axis=1)\n",
    "    dimension_score_dfs[dim] = score_df  # Store each dimension's DataFrame\n",
    "    print(f\"\\n{dim.capitalize()} Scores DataFrame:\\n\", score_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_rknr7b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting 3 dimensions for all posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_posts = pd.read_csv(\"../data/posts_final.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text but keep sentence structure due to sentence-level classification\n",
    "def clean_text(row):\n",
    "    text = str(row[0])\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'[^\\w\\s\\.\\?\\!]', '', text)  # Remove special characters except for ., ?, !\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = text.replace('x200b', '') # Remove x200b\n",
    "    return text\n",
    "\n",
    "cleaned_test_comment = clean_text(test_comment)\n",
    "print(cleaned_test_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_posts['body_clean'] = m_posts[[\"body\"]].astype({\"body\":\"string\"}).apply(clean_text,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_knowledge_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['body_clean'], 'knowledge')\n",
    "    return pd.Series([mean, max_score, min_score, std], index=['knowledge_mean', 'knowledge_max', 'knowledge_min', 'knowledge_std'])\n",
    "\n",
    "m_posts[['knowledge_mean', 'knowledge_max', 'knowledge_min', 'knowledge_std']] = m_posts.apply(compute_knowledge_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['body_clean'], 'similarity')\n",
    "    return pd.Series([mean, max_score, min_score, std], index=['similarity_mean', 'similarity_max', 'similarity_min', 'similarity_std'])\n",
    "\n",
    "m_posts[['similarity_mean', 'similarity_max', 'similarity_min', 'similarity_std']] = m_posts.apply(compute_similarity_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trust_scores(row):\n",
    "    mean, max_score, min_score, std = model.compute_score_split(row['body_clean'], 'trust')\n",
    "    return pd.Series([mean, max_score, min_score, std], index=['trust_mean', 'trust_max', 'trust_min', 'trust_std'])\n",
    "\n",
    "m_posts[['trust_mean', 'trust_max', 'trust_min', 'trust_std']] = m_posts.apply(compute_trust_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # examples\n",
    "# sentences = {\n",
    "# 'knowledge' : [\n",
    "#     \"Only a fully trained Jedi Knight, with The Force as his ally, will conquer Vader and his Emperor. If you end your training now, if you choose the quick and easy path, as Vader did, you will become an agent of evil\",\n",
    "#     \"Well, in layman's terms, you use a rotating magnetic field to focus a narrow beam of gravitons; these in turn fold space-time consistent with Weyl tensor dynamics until the space-time curvature becomes infinitely large and you have a singularity\",\n",
    "#     \"Since positronic signatures have only been known to emanate from androids such as myself, it is logical to theorize that there is an android such as myself on Kolarus III\",\n",
    "# ],\n",
    "\n",
    "# 'power' : [\n",
    "#     \"Now if you don't want to be the fifth person ever to die in meta-shock from a planar rift, I suggest you get down behind that desk and don't move until we give you the signal\",\n",
    "#     \"You can ask any price you want, but you must give me those letters \",\n",
    "#     \"Right now you're in no position to ask questions! And your snide remarks...\"\n",
    "# ],\n",
    "\n",
    "# 'status' : [\n",
    "#     \"I want to thank you, sir, for giving me the opportunity to work\",\n",
    "#     \"Frankie, you're a good old man, and you've been loyal to my Father for years...so I hope you can explain what you mean\",\n",
    "#     \"And we drink to her, and we all congratulate her on her wonderful accomplishment during this last year...her great success in A Doll's House!\"\n",
    "# ],\n",
    "\n",
    "# 'trust' : [\n",
    "#     \"I'm trying to tell you – and this is where you have to trust me – but, I think your life might be in real danger\",\n",
    "#     \"Mr. Lebowski is prepared to make a generous offer to you to act as courier once we get instructions for the money\",\n",
    "#     \"Take the Holy Gospels in your hand and swear to tell the whole truth concerning everything you will be asked\"\n",
    "# ],\n",
    "\n",
    "# 'support' : [\n",
    "#     \"I'm sorry, I just feel like... I know I shouldn't ask, I just need some kind of help, I just, I have a deadline tomorrow\",\n",
    "#     \"Look, Dave, I know that you're sincere and that you're trying to do a competent job, and that you're trying to be helpful, but I can assure the problem is with the AO-units, and with your test gear\",\n",
    "#     \"Well... listen, if you need any help, you know, back up, call me, OK?\"\n",
    "# ],\n",
    "\n",
    "# 'romance' : [\n",
    "#     \"I'm going to marry the woman I love\",\n",
    "#     \"If you are truly wild at heart, you'll fight for your dreams... Don’t turn away from love, Sailor \",\n",
    "#     \"You admit to me you do not love your fiance?\"\n",
    "# ],\n",
    "\n",
    "# 'identity' : [\n",
    "#     \"Hey, I know what I'm talkin' about, black women ain't the same as white women \",\n",
    "#     \"That's how it was in the old world, Pop, but this is not Sicily\",\n",
    "#     \"But, as you are so fond of observing, Doctor, I'm not human\"\n",
    "# ],\n",
    "\n",
    "# 'fun' : [\n",
    "#     \"It’s just funny...who needs a serial psycho in the woods with a chainsaw when we have ourselves\",\n",
    "#     \"I do enjoy playing bingo, if you'd like to join me for a game tomorrow night at church you’re welcome to\",\n",
    "#     \"Oh, I'm sure it’s a lot of fun, 'cause the Incas did it, you know, and-and they-they-they were a million laughs\"\n",
    "# ],\n",
    "\n",
    "# 'conflict' : [\n",
    "#     \"Forgive me for askin', son, and I don’t mean to belabor the obvious, but why is it that you’ve got your head so far up your own ass?\",\n",
    "#     \"If you're lying to me you poor excuse for a human being, I'm gonna blow your brains all over this car\",\n",
    "#     \"I couldn't give a shit if you believe me or not, and frankly I'm too tired to prove it to you\"\n",
    "# ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for dim in sentences:\n",
    "#     print(f' === {dim.upper()} ===')\n",
    "#     for s in sentences[dim]:\n",
    "#         score = model.compute_score(s, dim)\n",
    "#         print (f'{s} -- {dim}={score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
