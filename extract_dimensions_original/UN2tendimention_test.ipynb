{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd404dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from features.embedding_features import ExtractWordEmbeddings\n",
    "from models.lstm import LSTMClassifier\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenize = TweetTokenizer().tokenize\n",
    "from nltk import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "dimensions_list = ['support', 'knowledge', 'conflict', 'power', 'similarity', 'fun', 'status', 'trust', 'identity', 'romance']\n",
    "\n",
    "class TenDimensionsClassifier:\n",
    "\tdef __init__(self, models_dir = './models/lstm_trained_models', \n",
    "\t\tembeddings_dir = './embeddings', is_cuda=False):\n",
    "\t\t\"\"\"\n",
    "\t\t@param models_dir: the directory where the LSTM models are stored\n",
    "\t\t@param embeddings_dir: the directory where the embeddings are stored. The directory must contain the following subdirectories:\n",
    "\t\t                       word2vec/GoogleNews-vectors-negative300.wv\n",
    "\t\t                       fasttext/wiki-news-300d-1M-subword.wv\n",
    "\t\t                       glove/glove.42B.300d.wv\n",
    "\t\t@param is_cuda: to enable cuda\n",
    "\t\t\"\"\"\n",
    "\t\tself.is_cuda = is_cuda \n",
    "\t\tself.models_dir = models_dir\n",
    "\t\tself.embeddings_dir = embeddings_dir\n",
    "\n",
    "\t\t#load embeddings\n",
    "\t\tself.em_glove = ExtractWordEmbeddings('glove' ,emb_dir=self.embeddings_dir)\n",
    "\t\tself.em_word2vec = ExtractWordEmbeddings('word2vec', emb_dir=self.embeddings_dir)\n",
    "\t\tself.em_fasttext = ExtractWordEmbeddings('fasttext', emb_dir=self.embeddings_dir)\n",
    "\t\tself.dimensions_list = ['support', 'knowledge', 'conflict', 'power', 'similarity', 'fun', 'status', 'trust', 'identity', 'romance']\n",
    "\n",
    "\t\t#load models\n",
    "\t\tself.dim2model = {}\n",
    "\t\tself.dim2embedding = {}\n",
    "\n",
    "\t\tfor dim in self.dimensions_list:\n",
    "\t\t\tmodel = LSTMClassifier(embedding_dim=300, hidden_dim=300)\n",
    "\t\t\tif self.is_cuda:\n",
    "\t\t\t\tprint(f'Torch version: {torch.__version__}')\n",
    "\t\t\t\tprint(f'Torch CUDA available : {torch.cuda.is_available()}')\n",
    "\t\t\t\tif torch.cuda.is_available():\n",
    "\t\t\t\t\tprint(f'Torch current device : {torch.cuda.current_device()}')\n",
    "\t\t\t\t\tprint(f'Torch device count : {torch.cuda.device_count()}')\n",
    "\t\t\t\t\tprint(f'Torch device name : {torch.cuda.get_device_name(0)}')\n",
    "\t\t\t\t\tmodel.cuda()\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint('Cuda not available. Instantiated the TenDimensionsClassifier with CUDA=False')\n",
    "\t\t\t\t\tself.is_cuda = False \n",
    "\t\t\tmodel.eval()\n",
    "\t\t\tfor modelname in os.listdir(self.models_dir):\n",
    "\t\t\t\tif ('-best.lstm' in modelname) & (dim in modelname):\n",
    "\t\t\t\t\tbest_state = torch.load(join(self.models_dir, modelname), map_location='cpu')\n",
    "\t\t\t\t\tmodel.load_state_dict(best_state)\n",
    "\t\t\t\t\tif 'glove' in modelname:\n",
    "\t\t\t\t\t\tem = self.em_glove\n",
    "\t\t\t\t\telif 'word2vec' in modelname:\n",
    "\t\t\t\t\t\tem = self.em_word2vec\n",
    "\t\t\t\t\telif 'fasttext' in modelname:\n",
    "\t\t\t\t\t\tem = self.em_fasttext\n",
    "\t\t\t\t\tself.dim2model[dim] = model\n",
    "\t\t\t\t\tself.dim2embedding[dim] = em\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\n",
    "\tdef _parse_input_dimensions(self, d):\n",
    "\t\tif d is None:\n",
    "\t\t\treturn self.dimensions_list\n",
    "\t\telif isinstance(d, str):\n",
    "\t\t\treturn [d]\n",
    "\t\telif isinstance(d, list) or isinstance(d, tuple):\n",
    "\t\t\treturn d\n",
    "\t\telse:\n",
    "\t\t\traise Exception('Unrecognized input for dimension or dimension list: %s'%d)\n",
    "\n",
    "\n",
    "\tdef compute_score(self, text, dimensions=None):\n",
    "\t\t\"\"\"\n",
    "\t\tComputed dimension(s) scores on the whole input text\n",
    "\t\t@param text: the input text \n",
    "\t\t@param dimensions: a string representing the dimension or a list of strings for \n",
    "\t\t                   multiple dimensions. None triggers the computation of all dimensions\n",
    "\t\t@return the confidence score for the selected dimension\n",
    "\t\t        a dictionary dimension:score is returned if multiple dimensions were specified\n",
    "\t\t        None (or dimension:None) is returned when the dimension could not be computed\n",
    "\t\t\"\"\"\n",
    "\t\tdimension_scores = {d:None for d in self._parse_input_dimensions(dimensions)}\n",
    "\t\tif text is not None and text != '':\n",
    "\t\t\tfor dim in dimension_scores:\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tmodel = self.dim2model[dim]\n",
    "\t\t\t\t\tem = self.dim2embedding[dim]\n",
    "\t\t\t\t\tinput_ = em.obtain_vectors_from_sentence(tokenize(text), True)\n",
    "\t\t\t\t\tinput_ = torch.tensor(input_).float().unsqueeze(0)\n",
    "\t\t\t\t\tif self.is_cuda:\n",
    "\t\t\t\t\t\tinput_ = input_.cuda()\n",
    "\t\t\t\t\toutput = model(input_)\n",
    "\t\t\t\t\tscore = torch.sigmoid(output).item()\n",
    "\t\t\t\t\tdimension_scores[dim] = score\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tpass\n",
    "\t\tif len(dimension_scores) == 1:\n",
    "\t\t\treturn list(dimension_scores.values())[0]\n",
    "\t\telse:\n",
    "\t\t\treturn dimension_scores\n",
    "\n",
    "\n",
    "\tdef compute_score_split(self, text, dimensions=None, min_tokens=3):\n",
    "\t\t\"\"\"\n",
    "\t\tComputed dimension(s) scores on each sentence of the input text and returns aggreagated \n",
    "\t\tstats (avg and max)\n",
    "\t\t@param text: the input text \n",
    "\t\t@param dimensions: a string representing the dimension or a list of strings for \n",
    "\t\t                   multiple dimensions. None triggers the computation of all dimensions\n",
    "\t\t       min_tokens: the minimum number of tokens in a sentence for the dimension to be computed\n",
    "\t\t@return a tuple (avg, max, min, std) of confidence scores for the selected dimension\n",
    "\t\t        a dictionary dimension:(avg, max, min, std) is returned if multiple dimensions were specified\n",
    "\t\t        None (or dimension:None) is returned when the dimension could not be computed\n",
    "\t\t\"\"\"\n",
    "\t\tdimension_scores = {d:(None,None) for d in self._parse_input_dimensions(dimensions)}\n",
    "\t\tif text is not None and text != '':\n",
    "\t\t\tfor dim in dimension_scores:\n",
    "\t\t\t\tscores = []\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tsentences = sent_tokenize(text)\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tsentences = [text]\n",
    "\n",
    "\t\t\t\tfor sent in sentences:\n",
    "\t\t\t\t\tsent = str(sent)\n",
    "\t\t\t\t\tif sent is not None and sent != '' and sent != 'nan' and len(sent.split()) >= min_tokens:\n",
    "\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\tscore = self.compute_score(sent, dim)\n",
    "\t\t\t\t\t\t\tif score is not None:\n",
    "\t\t\t\t\t\t\t\tscores.append(score)\n",
    "\t\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\t\tpass\n",
    "\t\t\t\tif scores:\n",
    "\t\t\t\t\tdimension_scores[dim] = (np.mean(scores), np.max(scores), np.min(scores), np.std(scores))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdimension_scores[dim] = (None, None, None, None)\n",
    "\t\tif len(dimension_scores) == 1:\n",
    "\t\t\treturn list(dimension_scores.values())[0]\n",
    "\t\telse:\n",
    "\t\t\treturn dimension_scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
